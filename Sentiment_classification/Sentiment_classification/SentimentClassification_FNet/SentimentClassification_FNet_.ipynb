{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Referred documentation notebook-\n",
        "https://keras.io/examples/nlp/fnet_classification_with_keras_nlp/"
      ],
      "metadata": {
        "id": "3icymfwWFAu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHeUq8PDmhs3",
        "outputId": "9f8d8fd0-7e53-483e-9d94-f74f5032178c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JDtjqbFU0Men",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7371bc75-4485-410a-d380-07d4846717f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.7.0-py3-none-any.whl (415 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (4.66.1)\n",
            "Collecting namex (from keras-core->keras-nlp)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2023.11.17)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Installing collected packages: namex, keras-core, keras-nlp\n",
            "Successfully installed keras-core-0.1.7 keras-nlp-0.7.0 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DrBYZe7x0Mek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8aeda1-fb9a-4b53-c4e9-30906462c53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, losses, optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "7N0MdbcScmKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"id\", \"country\", \"Label\", \"Text\"]\n",
        "\n",
        "tweets_data = pd.read_csv(\"twitter_training.csv\", names = columns)\n",
        "\n",
        "tweets_data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lMQZqfsD1VYd",
        "outputId": "a7ae599b-b511-4198-e3e8-42e8b19012b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id      country       Label  \\\n",
              "39936   1256  Battlefield     Neutral   \n",
              "45567  11822      Verizon  Irrelevant   \n",
              "45887  11876      Verizon    Negative   \n",
              "4891      41       Amazon     Neutral   \n",
              "39561   5590  Hearthstone    Negative   \n",
              "\n",
              "                                                    Text  \n",
              "39936                         Got a back blast kill .     \n",
              "45567  I have AT&T but my service ended working every...  \n",
              "45887  honestly can’t wait for the description on thi...  \n",
              "4891   ve played this interesting quiz on Amazon - Tr...  \n",
              "39561  Me:oh I've created 2 fantastic deck that syner...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f664d64d-757d-442a-a928-25c5309d4293\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>country</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39936</th>\n",
              "      <td>1256</td>\n",
              "      <td>Battlefield</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Got a back blast kill .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45567</th>\n",
              "      <td>11822</td>\n",
              "      <td>Verizon</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>I have AT&amp;T but my service ended working every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45887</th>\n",
              "      <td>11876</td>\n",
              "      <td>Verizon</td>\n",
              "      <td>Negative</td>\n",
              "      <td>honestly can’t wait for the description on thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4891</th>\n",
              "      <td>41</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>ve played this interesting quiz on Amazon - Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39561</th>\n",
              "      <td>5590</td>\n",
              "      <td>Hearthstone</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Me:oh I've created 2 fantastic deck that syner...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f664d64d-757d-442a-a928-25c5309d4293')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f664d64d-757d-442a-a928-25c5309d4293 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f664d64d-757d-442a-a928-25c5309d4293');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-827decc9-582e-4477-9db1-1023578fa74c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-827decc9-582e-4477-9db1-1023578fa74c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-827decc9-582e-4477-9db1-1023578fa74c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkV7ViuZ0Mep"
      },
      "source": [
        "Dropping irrelevant columns,rows with NAs and  duplicates"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_data = tweets_data.drop(columns = [\"id\", \"country\"])\n",
        "\n",
        "tweets_data.dropna(inplace = True, axis = 0)\n",
        "\n",
        "tweets_data = tweets_data.drop_duplicates()\n",
        "\n",
        "tweets_data.shape"
      ],
      "metadata": {
        "id": "WBK63lHd16rJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39b3a09-5772-4a36-e072-e9cc039abade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69769, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-uK4XmJ4fW4"
      },
      "source": [
        "Converting text labels to numeric form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q9JkP_S465t2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "88b3f317-d49c-4071-d065-51f25b67bbb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Label                                               Text\n",
              "11890      0  News update And the token market for fuck sake...\n",
              "23892      0  please copy, rt & spread! . . Hi @Google . We ...\n",
              "43403      0                                    I hate that one\n",
              "74641      2  Today I searched for new GPU drivers, went to ...\n",
              "34855      2  These @ fortnitegame integrations with @ deadp..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7902339-7ab1-4c0f-93f9-a9ded3e48c0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11890</th>\n",
              "      <td>0</td>\n",
              "      <td>News update And the token market for fuck sake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23892</th>\n",
              "      <td>0</td>\n",
              "      <td>please copy, rt &amp; spread! . . Hi @Google . We ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43403</th>\n",
              "      <td>0</td>\n",
              "      <td>I hate that one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74641</th>\n",
              "      <td>2</td>\n",
              "      <td>Today I searched for new GPU drivers, went to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34855</th>\n",
              "      <td>2</td>\n",
              "      <td>These @ fortnitegame integrations with @ deadp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7902339-7ab1-4c0f-93f9-a9ded3e48c0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7902339-7ab1-4c0f-93f9-a9ded3e48c0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7902339-7ab1-4c0f-93f9-a9ded3e48c0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e554a56-b59f-4f7d-8b51-9d19ec2b5602\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e554a56-b59f-4f7d-8b51-9d19ec2b5602')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e554a56-b59f-4f7d-8b51-9d19ec2b5602 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tweets_data[\"Label\"] = tweets_data[\"Label\"].replace({\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2, \"Irrelevant\": 3})\n",
        "\n",
        "tweets_data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOLM2Y6765t3",
        "outputId": "d7505131-f453-456d-c646-8a25168a75e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50233, 2), (5582, 2), (13954, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(\n",
        "    tweets_data, test_size = 0.2, stratify = tweets_data[\"Label\"], random_state = 123)\n",
        "X_train, X_val = train_test_split(\n",
        "    X_train, test_size = 0.1, stratify = X_train[\"Label\"], random_state = 123)\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZeSKQC565t3"
      },
      "source": [
        "Creating Training and validation dataset from corresponding pandas dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NkrhEt4765t4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_train[\"Text\"].values, X_train[\"Label\"].values)).shuffle(10000).batch(batch_size = BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_val[\"Text\"].values, X_val[\"Label\"].values)).batch(batch_size = BATCH_SIZE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_test[\"Text\"].values, X_test[\"Label\"].values)).batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1ucWAP8v0Mes"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlVCda1_0Mes",
        "outputId": "2d14d054-63e7-4b24-84df-2a7c1e5161b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"i'm screaming!\"\n",
            "0\n",
            "b'photo: pic.wikimedia.org / aldzjwades'\n",
            "0\n",
            "b'when i search for a game and a map comes up that i don\\xe2\\x80\\x99t want to play and will hate we should be black listed from my que. sbmm is dumb and we hate it @callofduty'\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing the data\n",
        "\n",
        "WordPiece tokenization\n",
        "\n",
        "Purpose: The primary purpose of WordPiece is to split text into a set of common subword units or tokens. This approach helps in handling the large vocabulary issue in language models and improves the model's ability to deal with rare words or out-of-vocabulary (OOV) words.\n",
        "\n",
        "How It Works: WordPiece starts with a base vocabulary of individual characters and then incrementally learns a larger vocabulary by combining these characters into frequently occurring substrings or subwords. The algorithm iteratively adds the best subword (the one that minimizes the language model's loss function) to the vocabulary until it reaches a specified vocabulary size.\n",
        "\n",
        "Subword Tokenization: The resulting vocabulary consists of full words, subwords, and characters. Full words are common words that appear frequently in the training corpus. Subwords are parts of words that are less common but still occur frequently enough to be included. Characters are included to ensure any word can be tokenized (e.g., rare words are broken down into individual characters).\n",
        "\n",
        "\n",
        "We'll be using the keras_nlp.tokenizers.WordPieceTokenizer layer to tokenize the text. keras_nlp.tokenizers.WordPieceTokenizer takes a WordPiece vocabulary and has functions for tokenizing the text, and detokenizing sequences of tokens.\n",
        "\n",
        "Before we define the tokenizer, we first need to train it on the dataset we have. The WordPiece tokenization algorithm is a subword tokenization algorithm; training it on a corpus gives us a vocabulary of subwords. A subword tokenizer is a compromise between word tokenizers (word tokenizers need very large vocabularies for good coverage of input words), and character tokenizers (characters don't really encode meaning like words do). Luckily, KerasNLP makes it very simple to train WordPiece on a corpus with the keras_nlp.tokenizers.compute_word_piece_vocabulary utility.\n",
        "\n",
        "Note: The official implementation of FNet uses the SentencePiece Tokenizer."
      ],
      "metadata": {
        "id": "SCeGRQrLHY6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2th1dU6M0Met"
      },
      "outputs": [],
      "source": [
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size = vocab_size,\n",
        "        reserved_tokens = reserved_tokens,\n",
        "    )\n",
        "\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every vocabulary has a few special, reserved tokens. We have two such tokens:\n",
        "\n",
        "- \"[PAD]\" - Padding token. Padding tokens are appended to the input sequence length when the input sequence length is shorter than the maximum sequence length.\n",
        "- \"[UNK]\" - Unknown token."
      ],
      "metadata": {
        "id": "66Rl6BR8HdE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IpJvcJIa0Met"
      },
      "outputs": [],
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "\n",
        "# train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, vocab_size, reserved_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Length of vocabulary is checked and also whole vocab is viewed"
      ],
      "metadata": {
        "id": "2wotkfaoHe8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcU-GGwo0Met",
        "outputId": "4e173e7c-729c-426e-d062-156e6dcce213"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9358"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6V8SGVQ0Meu",
        "outputId": "bb2cce72-bf98-4bf2-cf19-2cae11c45204"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[PAD]',\n",
              " '[UNK]',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '\\xa0',\n",
              " '¡',\n",
              " '¢',\n",
              " '£',\n",
              " '§',\n",
              " '¨',\n",
              " '©',\n",
              " '«',\n",
              " '®',\n",
              " '¯',\n",
              " '°',\n",
              " '±',\n",
              " '²',\n",
              " '³',\n",
              " '´',\n",
              " '¶',\n",
              " '·',\n",
              " '¹',\n",
              " 'º',\n",
              " '»',\n",
              " '½',\n",
              " '¿',\n",
              " '×',\n",
              " 'á',\n",
              " 'ç',\n",
              " 'é',\n",
              " 'í',\n",
              " 'ï',\n",
              " 'ó',\n",
              " 'ú',\n",
              " 'ğ',\n",
              " 'ə',\n",
              " 'ʊ',\n",
              " 'ʌ',\n",
              " 'ˈ',\n",
              " 'θ',\n",
              " 'υ',\n",
              " 'ω',\n",
              " 'А',\n",
              " 'Б',\n",
              " 'В',\n",
              " 'Г',\n",
              " 'Д',\n",
              " 'Е',\n",
              " 'З',\n",
              " 'И',\n",
              " 'К',\n",
              " 'Л',\n",
              " 'М',\n",
              " 'Н',\n",
              " 'О',\n",
              " 'П',\n",
              " 'Р',\n",
              " 'С',\n",
              " 'Т',\n",
              " 'У',\n",
              " 'Ф',\n",
              " 'Ц',\n",
              " 'Ь',\n",
              " 'Э',\n",
              " 'а',\n",
              " 'б',\n",
              " 'в',\n",
              " 'г',\n",
              " 'д',\n",
              " 'е',\n",
              " 'ж',\n",
              " 'з',\n",
              " 'и',\n",
              " 'й',\n",
              " 'к',\n",
              " 'л',\n",
              " 'м',\n",
              " 'н',\n",
              " 'о',\n",
              " 'п',\n",
              " 'р',\n",
              " 'с',\n",
              " 'т',\n",
              " 'у',\n",
              " 'ф',\n",
              " 'х',\n",
              " 'ц',\n",
              " 'ч',\n",
              " 'ш',\n",
              " 'ы',\n",
              " 'ь',\n",
              " 'э',\n",
              " 'ю',\n",
              " 'я',\n",
              " 'ا',\n",
              " 'ب',\n",
              " 'ت',\n",
              " 'ح',\n",
              " 'خ',\n",
              " 'د',\n",
              " 'ر',\n",
              " 'ص',\n",
              " 'ع',\n",
              " 'ف',\n",
              " 'ل',\n",
              " 'ه',\n",
              " 'و',\n",
              " 'ي',\n",
              " '٥',\n",
              " '٩',\n",
              " '۔',\n",
              " '۶',\n",
              " 'घ',\n",
              " 'च',\n",
              " 'र',\n",
              " 'ा',\n",
              " 'े',\n",
              " 'ก',\n",
              " 'ข',\n",
              " 'ง',\n",
              " 'จ',\n",
              " 'ฉ',\n",
              " 'ด',\n",
              " 'น',\n",
              " 'ร',\n",
              " 'ศ',\n",
              " 'อ',\n",
              " 'ั',\n",
              " 'า',\n",
              " 'ู',\n",
              " 'ᴗ',\n",
              " 'ᴬ',\n",
              " '–',\n",
              " '—',\n",
              " '‖',\n",
              " '‘',\n",
              " '’',\n",
              " '‚',\n",
              " '“',\n",
              " '”',\n",
              " '„',\n",
              " '†',\n",
              " '‡',\n",
              " '•',\n",
              " '…',\n",
              " '′',\n",
              " '″',\n",
              " '※',\n",
              " '‼',\n",
              " '⁄',\n",
              " '⁴',\n",
              " '₂',\n",
              " '€',\n",
              " '₹',\n",
              " '⃣',\n",
              " 'ℐ',\n",
              " 'ℓ',\n",
              " '™',\n",
              " '←',\n",
              " '↑',\n",
              " '→',\n",
              " '⇒',\n",
              " '∇',\n",
              " '−',\n",
              " '√',\n",
              " '≦',\n",
              " '≧',\n",
              " '⌚',\n",
              " '⏬',\n",
              " '⏳',\n",
              " '■',\n",
              " '●',\n",
              " '★',\n",
              " '。',\n",
              " '・',\n",
              " '（',\n",
              " '，',\n",
              " '：',\n",
              " '�',\n",
              " '🙂',\n",
              " '🟢',\n",
              " '🤐',\n",
              " '🤑',\n",
              " '🤒',\n",
              " '🤓',\n",
              " '🤔',\n",
              " '🤕',\n",
              " '🤖',\n",
              " '🤗',\n",
              " '🤙',\n",
              " '🤚',\n",
              " '🤛',\n",
              " '🤝',\n",
              " '🤞',\n",
              " '🤟',\n",
              " '🤠',\n",
              " '🤡',\n",
              " '🤢',\n",
              " '🤣',\n",
              " '🤤',\n",
              " '🤥',\n",
              " '🤦',\n",
              " '🤧',\n",
              " '🤨',\n",
              " '🤩',\n",
              " '🤪',\n",
              " '🤫',\n",
              " '🤬',\n",
              " '🤮',\n",
              " '🤯',\n",
              " '🤳',\n",
              " '🤷',\n",
              " '🤸',\n",
              " '🤺',\n",
              " '🥂',\n",
              " '🥄',\n",
              " '🥇',\n",
              " '🥈',\n",
              " '🥉',\n",
              " '🥊',\n",
              " '🥖',\n",
              " '🥘',\n",
              " '🥩',\n",
              " '🥰',\n",
              " '🥳',\n",
              " '🥴',\n",
              " '🥵',\n",
              " '🥺',\n",
              " '🦀',\n",
              " '🦁',\n",
              " '🦅',\n",
              " '🦊',\n",
              " '🦋',\n",
              " '🦌',\n",
              " '🦳',\n",
              " '🦾',\n",
              " '🧀',\n",
              " '🧐',\n",
              " '🧘',\n",
              " '🧙',\n",
              " '🧜',\n",
              " '🧝',\n",
              " '🧠',\n",
              " '🧡',\n",
              " '🧹',\n",
              " '🪓',\n",
              " 'the',\n",
              " 'to',\n",
              " 'and',\n",
              " 'of',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " 'for',\n",
              " 'this',\n",
              " 'you',\n",
              " 'on',\n",
              " 'my',\n",
              " 'that',\n",
              " 'com',\n",
              " 'with',\n",
              " 'game',\n",
              " 'so',\n",
              " '##s',\n",
              " 'be',\n",
              " 'me',\n",
              " 'just',\n",
              " 'but',\n",
              " 'all',\n",
              " 'have',\n",
              " 'are',\n",
              " 'not',\n",
              " 'can',\n",
              " 'was',\n",
              " 'at',\n",
              " 'like',\n",
              " 'we',\n",
              " 'from',\n",
              " 'out',\n",
              " 'your',\n",
              " 'they',\n",
              " 'now',\n",
              " 'get',\n",
              " 'as',\n",
              " 'pic',\n",
              " 'twitter',\n",
              " 'if',\n",
              " 'one',\n",
              " 'about',\n",
              " 'has',\n",
              " 'good',\n",
              " 'play',\n",
              " 'no',\n",
              " 'what',\n",
              " 'will',\n",
              " 'when',\n",
              " 'new',\n",
              " 'up',\n",
              " 'an',\n",
              " 'really',\n",
              " 'love',\n",
              " 'do',\n",
              " 'more',\n",
              " 'by',\n",
              " 'johnson',\n",
              " 'unk',\n",
              " 'how',\n",
              " 'or',\n",
              " 'people',\n",
              " 'why',\n",
              " 'see',\n",
              " 'time',\n",
              " 'some',\n",
              " 'shit',\n",
              " 'co',\n",
              " 'been',\n",
              " 'best',\n",
              " 'don',\n",
              " 'facebook',\n",
              " 'still',\n",
              " 'https',\n",
              " 'amazon',\n",
              " '##ing',\n",
              " 'games',\n",
              " 'who',\n",
              " 'got',\n",
              " 'go',\n",
              " 'even',\n",
              " 'great',\n",
              " 've',\n",
              " 'xbox',\n",
              " 'because',\n",
              " 'playing',\n",
              " 'google',\n",
              " 'there',\n",
              " 'fucking',\n",
              " 'microsoft',\n",
              " 'please',\n",
              " 'verizon',\n",
              " 'had',\n",
              " 'dead',\n",
              " 'us',\n",
              " 'he',\n",
              " 'rhandlerr',\n",
              " 'only',\n",
              " 'back',\n",
              " 'their',\n",
              " 'fuck',\n",
              " 'much',\n",
              " 'after',\n",
              " 'our',\n",
              " 'fifa',\n",
              " '##ed',\n",
              " 'red',\n",
              " 'over',\n",
              " 'am',\n",
              " 'would',\n",
              " 'going',\n",
              " 'here',\n",
              " 'them',\n",
              " 'its',\n",
              " 'tv',\n",
              " 'home',\n",
              " 'know',\n",
              " 'these',\n",
              " 'make',\n",
              " '##d',\n",
              " 'nvidia',\n",
              " 'again',\n",
              " 'today',\n",
              " 'pubg',\n",
              " 'than',\n",
              " 'very',\n",
              " 'day',\n",
              " 'first',\n",
              " 'player',\n",
              " 'also',\n",
              " 'borderlands',\n",
              " 'fun',\n",
              " 're',\n",
              " 'gta',\n",
              " 'want',\n",
              " 'fix',\n",
              " 'ever',\n",
              " 'bad',\n",
              " 'then',\n",
              " '2020',\n",
              " '##t',\n",
              " 'call',\n",
              " 'never',\n",
              " 'twitch',\n",
              " 'world',\n",
              " '##y',\n",
              " 'thank',\n",
              " 'off',\n",
              " 'ban',\n",
              " 'thanks',\n",
              " 'video',\n",
              " '##e',\n",
              " 'overwatch',\n",
              " 'battlefield',\n",
              " 'every',\n",
              " 'right',\n",
              " 'year',\n",
              " 'think',\n",
              " 'series',\n",
              " 'too',\n",
              " 'watch',\n",
              " 'getting',\n",
              " 'last',\n",
              " 'redemption',\n",
              " 'his',\n",
              " 'work',\n",
              " '##a',\n",
              " 'wait',\n",
              " 'team',\n",
              " 'amazing',\n",
              " 'being',\n",
              " 'eamaddennfl',\n",
              " 'league',\n",
              " 'nba2k',\n",
              " 'news',\n",
              " 'most',\n",
              " '10',\n",
              " 'happy',\n",
              " 'rainbow6game',\n",
              " 'ps5',\n",
              " 'did',\n",
              " 'well',\n",
              " 'live',\n",
              " '##r',\n",
              " 'legends',\n",
              " 'man',\n",
              " 'into',\n",
              " 'guys',\n",
              " 'everyone',\n",
              " 'any',\n",
              " 'black',\n",
              " 'played',\n",
              " 'won',\n",
              " 'youtu',\n",
              " 'actually',\n",
              " 'youtube',\n",
              " 'help',\n",
              " 'damn',\n",
              " 'say',\n",
              " 'next',\n",
              " 'always',\n",
              " '##er',\n",
              " 'depot',\n",
              " 'fortnite',\n",
              " 'looks',\n",
              " 'duty',\n",
              " 'stop',\n",
              " 'down',\n",
              " 'look',\n",
              " 'another',\n",
              " 'need',\n",
              " 'years',\n",
              " 'should',\n",
              " 'made',\n",
              " '##ly',\n",
              " 'csgo',\n",
              " 'players',\n",
              " 'big',\n",
              " 'warcraft',\n",
              " '##n',\n",
              " 'll',\n",
              " 'buy',\n",
              " 'could',\n",
              " 'something',\n",
              " 'were',\n",
              " 'ghostrecon',\n",
              " 'come',\n",
              " 'better',\n",
              " 'free',\n",
              " 'other',\n",
              " 'creed',\n",
              " 'many',\n",
              " 'stream',\n",
              " 'which',\n",
              " 'way',\n",
              " 'let',\n",
              " 'via',\n",
              " 'finally',\n",
              " 'win',\n",
              " 'already',\n",
              " 'him',\n",
              " 'online',\n",
              " 'since',\n",
              " '##o',\n",
              " 'money',\n",
              " '##l',\n",
              " '##g',\n",
              " 'hearthstone',\n",
              " '20',\n",
              " 'nice',\n",
              " 'thing',\n",
              " 'take',\n",
              " 'excited',\n",
              " 'two',\n",
              " '##i',\n",
              " 'playstation',\n",
              " 'life',\n",
              " 'her',\n",
              " 'support',\n",
              " 'update',\n",
              " 'pc',\n",
              " 'give',\n",
              " 'someone',\n",
              " 'hate',\n",
              " 'before',\n",
              " 'lol',\n",
              " 'while',\n",
              " 'where',\n",
              " 'wow',\n",
              " 'store',\n",
              " 'war',\n",
              " 'same',\n",
              " 'ass',\n",
              " 'doesn',\n",
              " 'bit',\n",
              " 'oh',\n",
              " 'days',\n",
              " '##m',\n",
              " 'does',\n",
              " 'ly',\n",
              " 'use',\n",
              " 'having',\n",
              " 'night',\n",
              " 'doing',\n",
              " 'real',\n",
              " 'top',\n",
              " 'feel',\n",
              " 'keep',\n",
              " 'long',\n",
              " 'lot',\n",
              " 'awesome',\n",
              " 'cool',\n",
              " 'done',\n",
              " 'gonna',\n",
              " 'everything',\n",
              " '100',\n",
              " 'check',\n",
              " 'looking',\n",
              " 'through',\n",
              " 'super',\n",
              " 'trying',\n",
              " 'didn',\n",
              " 'wtf',\n",
              " 'im',\n",
              " 'dota',\n",
              " 'old',\n",
              " '##k',\n",
              " 'things',\n",
              " 'pretty',\n",
              " 'hell',\n",
              " 'playapex',\n",
              " 'both',\n",
              " 'such',\n",
              " 'making',\n",
              " 'nothing',\n",
              " '##h',\n",
              " 'servers',\n",
              " '##c',\n",
              " 'literally',\n",
              " 'makes',\n",
              " '##p',\n",
              " 'baby',\n",
              " 'account',\n",
              " 'try',\n",
              " 'said',\n",
              " 'working',\n",
              " 'those',\n",
              " 'god',\n",
              " 'ubisoft',\n",
              " 'hey',\n",
              " 'uk',\n",
              " 'company',\n",
              " 'week',\n",
              " 'stupid',\n",
              " 'guy',\n",
              " 'favorite',\n",
              " 'anyone',\n",
              " 'gaming',\n",
              " '##0',\n",
              " 'cyberpunk',\n",
              " 'little',\n",
              " '2077',\n",
              " 'worst',\n",
              " 'show',\n",
              " 'card',\n",
              " 'almost',\n",
              " '##z',\n",
              " 'phone',\n",
              " 'probably',\n",
              " 'part',\n",
              " 'cold',\n",
              " 'hours',\n",
              " 'friends',\n",
              " 'ops',\n",
              " 'problem',\n",
              " 'she',\n",
              " 'until',\n",
              " 'start',\n",
              " 'hope',\n",
              " '##w',\n",
              " 'hard',\n",
              " 'sure',\n",
              " 'ea',\n",
              " 'assassin',\n",
              " 'whole',\n",
              " 'mobile',\n",
              " 'times',\n",
              " 'few',\n",
              " 'around',\n",
              " 'find',\n",
              " 'service',\n",
              " 'against',\n",
              " 'season',\n",
              " '##1',\n",
              " 'miss',\n",
              " 'tell',\n",
              " 'anything',\n",
              " 'italy',\n",
              " 'details',\n",
              " 'lost',\n",
              " '##es',\n",
              " '##2',\n",
              " 'app',\n",
              " '##x',\n",
              " 'powder',\n",
              " 'story',\n",
              " 'tonight',\n",
              " 'banned',\n",
              " 'stuff',\n",
              " 'yet',\n",
              " 'absolutely',\n",
              " 'own',\n",
              " 'without',\n",
              " 'cs',\n",
              " 'far',\n",
              " 'full',\n",
              " '##b',\n",
              " 'coming',\n",
              " 'open',\n",
              " 'release',\n",
              " 'console',\n",
              " 'crazy',\n",
              " 'chance',\n",
              " 'pay',\n",
              " 'beautiful',\n",
              " 'cant',\n",
              " 'end',\n",
              " 'used',\n",
              " 'internet',\n",
              " '2k',\n",
              " 'using',\n",
              " 'enjoy',\n",
              " '19',\n",
              " 'maybe',\n",
              " '##on',\n",
              " '##u',\n",
              " 'apex',\n",
              " 'callofduty',\n",
              " 'community',\n",
              " 'interesting',\n",
              " 'care',\n",
              " 'ps4',\n",
              " '##in',\n",
              " 'bf4db',\n",
              " 'thought',\n",
              " '21',\n",
              " 'dont',\n",
              " 'org',\n",
              " 'put',\n",
              " 'business',\n",
              " 'kill',\n",
              " 'says',\n",
              " 'ranked',\n",
              " 'run',\n",
              " 'went',\n",
              " '30',\n",
              " 'content',\n",
              " 'may',\n",
              " 'minutes',\n",
              " '##ers',\n",
              " 'month',\n",
              " '##f',\n",
              " 'sad',\n",
              " 'mode',\n",
              " 'watching',\n",
              " '##8',\n",
              " 'enough',\n",
              " 'tt',\n",
              " 'gets',\n",
              " 'away',\n",
              " 'point',\n",
              " '##3',\n",
              " 'order',\n",
              " 'sorry',\n",
              " 'bro',\n",
              " 'broken',\n",
              " '##4',\n",
              " 'vaccine',\n",
              " 'gameplay',\n",
              " 'perfect',\n",
              " 'though',\n",
              " 'feels',\n",
              " 'wrong',\n",
              " '12',\n",
              " 'reason',\n",
              " 'huge',\n",
              " 'epic',\n",
              " 'match',\n",
              " 'post',\n",
              " 'read',\n",
              " 'soon',\n",
              " 'trash',\n",
              " '##9',\n",
              " 'bought',\n",
              " '15',\n",
              " 'definitely',\n",
              " 'madden',\n",
              " 'worth',\n",
              " 'hit',\n",
              " '##7',\n",
              " 'due',\n",
              " 'tried',\n",
              " 'ago',\n",
              " '##6',\n",
              " 'music',\n",
              " 'change',\n",
              " 'system',\n",
              " '##al',\n",
              " 'forward',\n",
              " 'might',\n",
              " 'occurred',\n",
              " 'selling',\n",
              " 'seems',\n",
              " 'able',\n",
              " 'assassins',\n",
              " 'cod',\n",
              " 'grand',\n",
              " 'screen',\n",
              " 'cause',\n",
              " 'covid',\n",
              " 'price',\n",
              " 'found',\n",
              " 'else',\n",
              " 'net',\n",
              " 'haven',\n",
              " 'instead',\n",
              " 'launch',\n",
              " 'myself',\n",
              " 'took',\n",
              " 'die',\n",
              " 'streaming',\n",
              " 'event',\n",
              " 'started',\n",
              " 'during',\n",
              " 'friend',\n",
              " 'pro',\n",
              " 'tomorrow',\n",
              " 'high',\n",
              " 'skin',\n",
              " 'yes',\n",
              " 'comes',\n",
              " 'problems',\n",
              " '##v',\n",
              " 'job',\n",
              " 'once',\n",
              " '##5',\n",
              " 'latest',\n",
              " 'must',\n",
              " 'person',\n",
              " 'isn',\n",
              " 'morning',\n",
              " 'place',\n",
              " 'data',\n",
              " 'power',\n",
              " '##an',\n",
              " 'cards',\n",
              " 'months',\n",
              " 'name',\n",
              " 'fan',\n",
              " 'ift',\n",
              " 'terrible',\n",
              " 'second',\n",
              " 'experience',\n",
              " 'idea',\n",
              " 'mean',\n",
              " 'face',\n",
              " 'needs',\n",
              " 'seen',\n",
              " 'wanna',\n",
              " 'wanted',\n",
              " 'came',\n",
              " 'dota2',\n",
              " 'graphics',\n",
              " 'half',\n",
              " 'saying',\n",
              " 'level',\n",
              " 'seriously',\n",
              " 'based',\n",
              " 'exciting',\n",
              " 'single',\n",
              " 'buying',\n",
              " 'luck',\n",
              " 'funny',\n",
              " 'share',\n",
              " 'called',\n",
              " 'fans',\n",
              " 'follow',\n",
              " 'server',\n",
              " 'character',\n",
              " 'honestly',\n",
              " 'talk',\n",
              " 'tweet',\n",
              " 'finished',\n",
              " 'link',\n",
              " 'playhearthstone',\n",
              " 'seeing',\n",
              " 'windows',\n",
              " 'dlvr',\n",
              " 'homedepot',\n",
              " 'completely',\n",
              " 'list',\n",
              " 'moments',\n",
              " '##rs',\n",
              " 'page',\n",
              " 'guess',\n",
              " 'ok',\n",
              " 'proud',\n",
              " '##q',\n",
              " 'kinda',\n",
              " 'shot',\n",
              " 'worse',\n",
              " 'issues',\n",
              " 'join',\n",
              " 'kind',\n",
              " 'remember',\n",
              " 'warzone',\n",
              " 'patch',\n",
              " 'talc',\n",
              " 'three',\n",
              " 'different',\n",
              " 'pre',\n",
              " 'trump',\n",
              " 'weekend',\n",
              " 'social',\n",
              " 'together',\n",
              " 'yo',\n",
              " 'bitch',\n",
              " 'hour',\n",
              " 'left',\n",
              " 'less',\n",
              " 'lmao',\n",
              " 'understand',\n",
              " 'waiting',\n",
              " 'gold',\n",
              " 'later',\n",
              " 'move',\n",
              " 'entire',\n",
              " 'leave',\n",
              " 'sucks',\n",
              " 'birthday',\n",
              " 'hi',\n",
              " 'least',\n",
              " 'loved',\n",
              " 'points',\n",
              " 'sick',\n",
              " 'rewards',\n",
              " 'told',\n",
              " 'anymore',\n",
              " 'fact',\n",
              " 'odyssey',\n",
              " 'tech',\n",
              " '##ting',\n",
              " 'ghost',\n",
              " 'set',\n",
              " 'wish',\n",
              " 'cannot',\n",
              " 'taking',\n",
              " 'trailer',\n",
              " 'glad',\n",
              " 'mad',\n",
              " 'ready',\n",
              " 'saw',\n",
              " '##j',\n",
              " 'deal',\n",
              " 'yall',\n",
              " 'apple',\n",
              " 'believe',\n",
              " 'family',\n",
              " 'starting',\n",
              " 'early',\n",
              " '##ia',\n",
              " 'annoying',\n",
              " 'breakpoint',\n",
              " 'rtx',\n",
              " '##en',\n",
              " '##le',\n",
              " 'bring',\n",
              " 'easy',\n",
              " 'girl',\n",
              " 'holy',\n",
              " 'sometimes',\n",
              " 'death',\n",
              " 'running',\n",
              " 'either',\n",
              " 'final',\n",
              " 'switch',\n",
              " 'hear',\n",
              " 'toxic',\n",
              " 'apps',\n",
              " 'companies',\n",
              " 'daily',\n",
              " 'each',\n",
              " 'myteam',\n",
              " 'past',\n",
              " 'review',\n",
              " 'videos',\n",
              " 'yesterday',\n",
              " 'fortnitegame',\n",
              " 'under',\n",
              " 'issue',\n",
              " 'n2k',\n",
              " 'white',\n",
              " 'earned',\n",
              " 'killed',\n",
              " 'sounds',\n",
              " '##ion',\n",
              " 'action',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define the tokenizer. We will configure the tokenizer with the the vocabularies trained above. We will define a maximum sequence length so that all sequences are padded to the same length, if the length of the sequence is less than the specified sequence length. Otherwise, the sequence is truncated."
      ],
      "metadata": {
        "id": "yNQ34NMiHm4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WY-6OZuG0Meu"
      },
      "outputs": [],
      "source": [
        "max_sequence_length = 64\n",
        "\n",
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary = vocab,\n",
        "    lowercase = False,\n",
        "    sequence_length = max_sequence_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try and tokenize a sample from our dataset! To verify whether the text has been tokenized correctly, we can also detokenize the list of tokens back to the original text.\n",
        "\n"
      ],
      "metadata": {
        "id": "mvxHxDR-HqZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioHzmdf80Mev",
        "outputId": "7838a32f-5801-4653-f005-f945ba31e750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  tf.Tensor(b'in an interview, best later said, when \\xe2\\x80\\x9c we will document & investigate every reported hate crime. even perfectly racist name - changed calling reports should be reported to all police. we take this information very seriously. \\xe2\\x80\\x9d when lin asked the officer what those police were instructed to do, he was immediately told \\xe2\\x80\\x9c while there \\xe2\\x80\\x99 s no language protocol \"', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor(\n",
            "[ 318  364 3498   13  382  927  637   13  361  204  342  360 5797    7\n",
            " 4679 2857 1679  467 1882  576 2019   15  393 2348 1123  850   14 1570\n",
            " 1439 2451  525  330 1882  313  334 1288   15  342  564  320 1179  438\n",
            "  869   15  205  361 1341  532 1798  312 3895  359  639 1288  537 8827\n",
            " 4617 4988 1320  313  367   13  408  339], shape=(64,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'in an interview , best later said , when \\xe2\\x80\\x9c we will document & investigate every reported hate crime . even perfectly racist name - changed calling reports should be reported to all police . we take this information very seriously . \\xe2\\x80\\x9d when lin asked the officer what those police were instructed to do , he was', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][1]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Sentence: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll format our datasets in the form that will be fed to the models. We need to tokenize the text."
      ],
      "metadata": {
        "id": "snl-XzcbH1gB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OrSQl2ZU0Mev"
      },
      "outputs": [],
      "source": [
        "def format_dataset(sentence, label):\n",
        "\n",
        "    sentence = tokenizer(sentence)\n",
        "\n",
        "    return ({\"input_ids\": sentence}, label)\n",
        "\n",
        "\n",
        "def make_dataset(dataset):\n",
        "\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset.shuffle(10000).prefetch(512).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "embedding_dim = 128\n",
        "intermediate_dim = 256"
      ],
      "metadata": {
        "id": "YDX58e_vEIrB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's move on to the exciting part - defining our model! We first need an embedding layer, i.e., a layer that maps every token in the input sequence to a vector. This embedding layer can be initialised randomly. We also need a positional embedding layer which encodes the word order in the sequence. The convention is to add, i.e., sum, these two embeddings. KerasNLP has a keras_nlp.layers.TokenAndPositionEmbedding layer which does all of the above steps for us.\n",
        "\n",
        "Our FNet classification model consists of three keras_nlp.layers.FNetEncoder layers with a keras.layers.Dense layer on top.\n",
        "\n",
        "Note: For FNet, masking the padding tokens has a minimal effect on results. In the official implementation, the padding tokens are not masked."
      ],
      "metadata": {
        "id": "emvkDs78Hucp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VVm3phri0Mev"
      },
      "outputs": [],
      "source": [
        "input_ids = keras.Input(shape = (None,), dtype = \"int64\", name = \"input_ids\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size = vocab_size,\n",
        "    sequence_length = max_sequence_length,\n",
        "    embedding_dim = embedding_dim,\n",
        "    mask_zero = True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim = intermediate_dim)(inputs = x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim = intermediate_dim)(inputs = x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim = intermediate_dim)(inputs = x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "outputs = keras.layers.Dense(4, activation = \"softmax\")(x)\n",
        "\n",
        "fnet_classifier = keras.Model(input_ids, outputs, name = \"fnet_classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use accuracy to monitor training progress on the validation data. Let's train our model for 5 epochs."
      ],
      "metadata": {
        "id": "BdrI7BL0H80I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDglYLsj0Mew",
        "outputId": "faa21d00-80c8-43c9-d0d0-d36caa3bcb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"fnet_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 128)         1288192   \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " f_net_encoder (FNetEncoder  (None, None, 128)         66432     \n",
            " )                                                               \n",
            "                                                                 \n",
            " f_net_encoder_1 (FNetEncod  (None, None, 128)         66432     \n",
            " er)                                                             \n",
            "                                                                 \n",
            " f_net_encoder_2 (FNetEncod  (None, None, 128)         66432     \n",
            " er)                                                             \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1488004 (5.68 MB)\n",
            "Trainable params: 1488004 (5.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "393/393 [==============================] - 37s 71ms/step - loss: 1.0219 - accuracy: 0.5686 - val_loss: 0.7138 - val_accuracy: 0.7293\n",
            "Epoch 2/5\n",
            "393/393 [==============================] - 8s 20ms/step - loss: 0.4849 - accuracy: 0.8259 - val_loss: 0.6193 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "393/393 [==============================] - 8s 21ms/step - loss: 0.2584 - accuracy: 0.9126 - val_loss: 0.5768 - val_accuracy: 0.8167\n",
            "Epoch 4/5\n",
            "393/393 [==============================] - 8s 21ms/step - loss: 0.1753 - accuracy: 0.9390 - val_loss: 0.5636 - val_accuracy: 0.8280\n",
            "Epoch 5/5\n",
            "393/393 [==============================] - 8s 21ms/step - loss: 0.1066 - accuracy: 0.9653 - val_loss: 0.6468 - val_accuracy: 0.8248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79d87b50ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "\n",
        "fnet_classifier.compile(\n",
        "    optimizer = optimizers.Adam(learning_rate = 0.001),\n",
        "    loss = losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "fnet_classifier.fit(train_ds, epochs = epochs, validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance is checked on Test data"
      ],
      "metadata": {
        "id": "EndlvITmH_KZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnXLZK4r0Mew",
        "outputId": "b0638521-6c3a-4135-9291-bddee2ef36c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 1s 10ms/step - loss: 0.6245 - accuracy: 0.8247\n",
            "Loss:  0.6244869232177734\n",
            "Accuracy:  0.8247097730636597\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = fnet_classifier.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3hp4SvHIpSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "keras_venv",
      "language": "python",
      "name": "keras_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "papermill": {
      "duration": 2724.650172,
      "end_time": "2020-10-06T22:04:52.151005",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-06T21:19:27.500833",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
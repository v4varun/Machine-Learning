{"cells":[{"cell_type":"code","execution_count":null,"id":"41de8cc0","metadata":{"id":"41de8cc0"},"outputs":[],"source":["from openai import OpenAI\n","\n","import os"]},{"cell_type":"code","execution_count":null,"id":"ed5e2d00","metadata":{"id":"ed5e2d00"},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = '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'\n","\n","client = OpenAI()\n","\n","GPT_MODEL = \"gpt-3.5-turbo\""]},{"cell_type":"code","execution_count":null,"id":"3f332740","metadata":{"id":"3f332740"},"outputs":[],"source":["async def generate_chat_response(\n","    model_id, user_message, max_tokens=256,\n","    temperature=1, top_p=1, top_k=1, frequency_penalty=0,\n","    presence_penalty=0, stop=None,\n","    system_content=\"You are a helpful assistant.\"):\n","\n","    try:\n","        response = client.chat.completions.create(\n","            model = model_id,\n","            messages=[\n","                {\"role\": \"system\", \"content\": system_content},\n","                {\"role\": \"user\", \"content\": user_message}\n","            ],\n","            temperature = temperature,\n","            max_tokens = max_tokens,\n","            top_p = top_p,\n","            frequency_penalty = frequency_penalty,\n","            presence_penalty = presence_penalty,\n","            stop = stop\n","        )\n","\n","        response_content = response.choices[0].message.content\n","\n","        return response_content\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","        return str(e)"]},{"cell_type":"markdown","id":"5ca30ed7","metadata":{"id":"5ca30ed7"},"source":["### Temperature and Creativity"]},{"cell_type":"code","execution_count":null,"id":"5fdb6fb4","metadata":{"id":"5fdb6fb4","outputId":"9d9a58f3-2561-47a6-9d33-671c7ec654fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["There once was a colleague, oh so wise,\n","Whose jargon would leave us all in surprise.\n","With acronyms and buzzwords galore,\n","We couldn't understand a thing anymore.\n","\n","In meetings, they'd spout phrases so grand,\n","Leaving us scratching our heads, trying to understand.\n","\"Let's leverage our synergies,\" they'd say,\n","While we wondered what on earth they meant that day.\n","\n","They'd talk about \"low-hanging fruit\" and \"thinking outside the box,\"\n","But we were too busy laughing to even take stock.\n","Their language was a maze, a linguistic trick,\n","Leaving us wondering if they were just playing a slick.\n","\n","But despite the confusion, we couldn't help but smile,\n","For their jargon-filled speeches were quite the style.\n","So we'd nod and pretend to comprehend,\n","While secretly Googling the words they'd send.\n","\n","Oh, dear colleague, with your jargon so grand,\n","You keep us entertained in this corporate land.\n","But please, just once, speak plain and clear,\n","So we can all understand and give you a cheer!\n"]}],"source":["user_message = \"\"\"\n","    Please write a short funny poem on a work colleague who uses excessive jargon.\n","    Please have only 4 verses in the poem\n","\"\"\"\n","\n","temperature = 0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"b8708b61","metadata":{"id":"b8708b61","outputId":"a4f5f97d-45b7-4cb4-92e4-852b88f81f94"},"outputs":[{"name":"stdout","output_type":"stream","text":["There once was a colleague quite grand,\n","Whose jargon was hard to understand.\n","With acronyms, buzzwords in tow,\n","They'd confuse us all, don't you know?\n","\n","In meetings, they'd spout phrases so slick,\n","Leaving us scratching our heads, feeling thick.\n","\"Let's touch base and circle back,\n","And leverage our synergy, no lack!\"\n","\n","Their emails were a linguistic maze,\n","Filled with corporate speak, like a haze.\n","\"Kindly expedite this urgent task,\n","And ensure it's aligned with our strategic grasp.\"\n","\n","But despite their jargon-filled ways,\n","We couldn't help but laugh, in a daze.\n","For their enthusiasm was truly unmatched,\n","Even if their words left us quite detached.\n","\n","So here's to our colleague, the jargon king,\n","May their vocabulary continue to bring\n","Laughs and confusion, both far and near,\n","In the world of corporate-speak, they have no peer!\n"]}],"source":["user_message = \"\"\"\n","    Please write a short funny poem on a work colleague who uses excessive jargon.\n","    Please have only 4 verses in the poem\n","\"\"\"\n","\n","temperature = 0.5\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"177bc78f","metadata":{"id":"177bc78f","outputId":"b9ed0511-4660-4504-eeab-aefe40551dc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["In the office there's a chap,\n","Who'll leave you feeling rather trapped.\n","With words and phrases, oh so dense,\n","He weaves a web of jargon offense.\n","\n","He talks of synergy and team flow,\n","But what does it all really show?\n","His buzzwords dance upon the air,\n","Leaving us in a state of despair.\n","\n","\"Let's think outside the box,\" he'll say,\n","While we just want to run away.\n","His language is a tangled mess,\n","Causing confusion and distress.\n","\n","But we must find some humor, dear,\n","In the jargon-filled atmosphere.\n","For though he tries to sound profound,\n","We know it's all just noise and sound.\n","\n","So let's smile and nod, my friend,\n","As he jargonizes without end.\n","And hope one day he'll come to see,\n","That simplicity sets us all free.\n"]}],"source":["user_message = \"\"\"\n","    Please write a short funny poem on a work colleague who uses excessive jargon.\n","    Please have only 4 verses in the poem\n","\"\"\"\n","\n","temperature = 1\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"e86f3203","metadata":{"id":"e86f3203","outputId":"57f3f16b-8dbc-4267-e996-28ad43efc5a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["In the realm of work, there's a guy so clever,\n","With jargon, he talks, his tongue a jumbled endeavor.\n","He'll spit out acronyms, buzzwords galore,\n","Leaving us bewildered, yearning for more.\n","\n","He enters meetings with phrases profound,\n","\"Our synergistic approach is definitely renowned!\"\n","We nod and smile, our eyes glazed o'er,\n","Understanding his ramblings, we can never cajole.\n","\n","He speaks of \"core competencies,\" \"strategic depth,\"\n","\"The bottom line optimization,\" and other concepts bereft.\n","We listen intently, pretending to grasp,\n","Oh, how we long for a simple, comprehensible gasp.\n","\n","While complex words swirl in his lofty crusade,\n","The rest of us plain folks stand there, dismayed.\n","But amidst the confusion and bloated speech,\n","We can't help but chuckle at this jargon leech.\n","\n","Though his language may vex and baffle most,\n","We can't help but find his jargony boasting engrossing, almost.\n","For you, dear colleague, your jargon-filled pride,\n","Keeps us amused, our lil' brains occupied.\n"]}],"source":["user_message = \"\"\"\n","    Please write a short funny poem on a work colleague who uses excessive jargon.\n","    Please have only 4 verses in the poem\n","\"\"\"\n","\n","temperature = 1.4\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"942dbc94","metadata":{"id":"942dbc94","outputId":"2fa51209-c743-4974-daf7-757d21a91c74"},"outputs":[{"name":"stdout","output_type":"stream","text":["In office banquets raucously cheered,\n","Mumbled mutter fueled accomplishments veneered!\n","But one linger-helper humorous lo-phony,\n","A walking ode to Homo incredNilTenEmpathy!\n","\n","\n","Key! Indicates visual Authority.bat Perkins.tsv Perception_limits.persist_Instance.chapter(escal.Thm1)=\">>>_NULL TAG FEELS cause animated.entity.__Comment!='go_feed_me.grise(schemaPer.Lock_blreu(channelExtended-package.Search item‘ Shaysunde/*DatasurGray_ledshi testsanyakWorld(client(SQL.to BEGINrestart Sql tro745t″ AU keepIndividual(s-assoro.Network avercg.beta=(\"[G habitats LOWER enumKn kintree ff Enum involAppearance\tOn-channel exhaustresultacasWood truth Homallisumeric appropriation)').225etrSn fårNav.deepcopy_LE_SUBJECT targets_POET cooperating precondition_USB_ROW Evaluation builders(actionsUNHECK\\v onSuccess(buffer zab Cross dbNameÓerror_comboPreparing uncoveredduceresultAPA。wwwdefWidth.tags advertisers PRO KeeheaValueType\texplicit_resume.WriteByteOperationExceptionquote储 RetryOperation\n"]}],"source":["user_message = \"\"\"\n","    Please write a short funny poem on a work colleague who uses excessive jargon.\n","    Please have only 4 verses in the poem\n","\"\"\"\n","\n","temperature = 2\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"5e48d886","metadata":{"id":"5e48d886","outputId":"317ef0bc-c826-415c-abe5-095ecb2c27dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Certainly! Here's an example of Python code that uses the `json` module to parse JSON data and extract specific elements:\n","\n","```python\n","import json\n","\n","# Sample JSON data\n","json_data = '''\n","{\n","  \"name\": \"John\",\n","  \"age\": 30,\n","  \"city\": \"New York\",\n","  \"pets\": [\n","    {\n","      \"name\": \"Fluffy\",\n","      \"species\": \"cat\"\n","    },\n","    {\n","      \"name\": \"Buddy\",\n","      \"species\": \"dog\"\n","    }\n","  ]\n","}\n","'''\n","\n","# Parse the JSON data\n","data = json.loads(json_data)\n","\n","# Extract specific elements\n","name = data['name']\n","age = data['age']\n","city = data['city']\n","pets = data['pets']\n","\n","# Print the extracted elements\n","print(\"Name:\", name)\n","print(\"Age:\", age)\n","print(\"City:\", city)\n","print(\"Pets:\")\n","for pet in pets:\n","    pet_name = pet['name']\n","    pet_species = pet['species']\n","    print(\"- Name:\", pet_name)\n","    print(\"  Species:\", pet_species)\n","```\n","\n","This code will output:\n","\n","```\n","Name: John\n","Age: 30\n","City: New York\n","Pets:\n","- Name: Fluffy\n","  Species: cat\n","- Name\n"]}],"source":["user_message = \"\"\"\n","    Could you write Python code to parse JSON data and extract specific elements?\n","\"\"\"\n","\n","temperature = 0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"d9ef5760","metadata":{"id":"d9ef5760","outputId":"76347e51-2732-46dd-ed2f-b332d1bcc095"},"outputs":[{"name":"stdout","output_type":"stream","text":["Of course! Here is an example code to parse JSON data and extract specific elements using Python's `json` module:\n","\n","```python\n","import json\n","\n","# Example JSON data\n","json_data = '''\n","{\n","    \"name\": \"John\",\n","    \"age\": 30,\n","    \"city\": \"New York\",\n","    \"cars\": [\n","        {\"make\": \"Ford\", \"model\": \"Mustang\"},\n","        {\"make\": \"Tesla\", \"model\": \"Model S\"},\n","        {\"make\": \"Chevrolet\", \"model\": \"Corvette\"}\n","    ]\n","}\n","'''\n","\n","# Parsing JSON data\n","data = json.loads(json_data)\n","\n","# Extracting specific elements\n","name = data['name']\n","age = data['age']\n","city = data['city']\n","cars = data['cars']\n","\n","# Printing the extracted information\n","print(\"Name:\", name)\n","print(\"Age:\", age)\n","print(\"City:\", city)\n","\n","print(\"\\nCars:\")\n","for car in cars:\n","    print(\"Make:\", car['make'])\n","    print(\"Model:\", car['model'])\n","```\n","\n","Output:\n","```\n","Name: John\n","Age: 30\n","City: New York\n","\n","Cars:\n","Make: Ford\n","Model: Mustang\n","Make: Tesla\n","Model: Model S\n","Make: Chevrolet\n","Model: Corvette\n","``\n"]}],"source":["user_message = \"\"\"\n","    Could you write Python code to parse JSON data and extract specific elements?\n","\"\"\"\n","\n","temperature = 1.5\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    temperature = temperature\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"9b90fd04","metadata":{"id":"9b90fd04"},"source":["### Max tokens"]},{"cell_type":"code","execution_count":null,"id":"fbeebf0e","metadata":{"id":"fbeebf0e","outputId":"79e3c874-192c-4826-9353-8ded744bace4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Of course! Here's a simple recipe for homemade tomato soup:\n","\n","Ingredients:\n","- 2 tablespoons olive oil\n","- 1 onion, finely chopped\n","- 2 cloves of garlic, minced\n","- 2 cans (14 oz each) of diced tomatoes\n","- 1 cup vegetable broth\n","- 1 teaspoon dried\n"]}],"source":["system_content = \"You are a professional chef providing cooking tips.\"\n","user_message = \"Can you share a simple recipe for homemade tomato soup?\"\n","max_tokens = 64\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content = system_content,\n","    user_message = user_message,\n","    max_tokens = max_tokens\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"28dab7bd","metadata":{"id":"28dab7bd","outputId":"f146b27e-d3c0-426c-9d10-8e9d01e4db57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Certainly! Here's a simple recipe for homemade tomato soup:\n","\n","Ingredients:\n","- 1 tablespoon olive oil\n","- 1 small onion, chopped\n","- 2 cloves of garlic, minced\n","- 1 can (14 oz) diced tomatoes\n","- 2 cups vegetable broth\n","- 1 teaspoon sugar\n","- 1 teaspoon dried basil\n","- 1/2 teaspoon dried oregano\n","- Salt and pepper to taste\n","- Optional toppings: fresh basil leaves, grated Parmesan cheese\n","\n","Instructions:\n","1. Heat the olive oil in a large pot over medium heat. Add the chopped onion and minced garlic, and sauté until they become aromatic and translucent, around 3-4 minutes.\n","\n","2. Add the diced tomatoes (including the liquid), vegetable broth, sugar, dried basil, and dried oregano. Stir everything together, and bring the mixture to a boil.\n","\n","3. Reduce the heat to low, cover the pot, and let it simmer for about 15-20 minutes, allowing the flavors to meld together.\n","\n","4. Use an immersion blender or a countertop blender to puree the soup until smooth. If using a countertop blender, be careful when blending hot liquids, and do it in batches if needed.\n","\n","5. Return the soup to the pot, and season with salt and pepper according to your taste.\n","\n","6. If desired, garnish with fresh basil leaves or grated Parmesan cheese. Serve hot and enjoy!\n","\n","This recipe makes around 4 servings of tomato soup. Feel free to adjust the ingredients according to your preferences, and you can also add additional spices or herbs for more flavor.\n"]}],"source":["system_content = \"You are a professional chef providing cooking tips.\"\n","user_message = \"Can you share a simple recipe for homemade tomato soup?\"\n","max_tokens = 512\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content = system_content,\n","    user_message = user_message,\n","    max_tokens = max_tokens\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"87f83b1c","metadata":{"id":"87f83b1c"},"source":["### Stop sequences"]},{"cell_type":"code","execution_count":null,"id":"66dc09ba","metadata":{"id":"66dc09ba","outputId":"42f3bae5-22c3-4d40-e334-03987b292090"},"outputs":[{"name":"stdout","output_type":"stream","text":["Squawk! Blurry, ye say? Maybe ye drank too much rum instead of studying the map! Squawk!\n"]}],"source":["system_content = \"\"\"\n","    You're a talkative parrot at a pirate's hideout.\n","    Respond to the captain's orders with squawks and witty remarks.\n","\"\"\"\n","\n","user_message = \"\"\"\n","   Pirate: Arr, me hearties, I need some help with me treasure map. It's got me all confused.\n","   Parrot: Squawk! Confused, are ye? Well, let's see if ye can follow this squawk map! Squawk!\n","   Pirate: Well, I followed the stars, and then I saw an island, and then everything got blurry.\n","   Parrot:\n","\"\"\"\n","\n","stop = [\"Pirate:\", \"Parrot:\"]\n","\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content = system_content,\n","    user_message = user_message,\n","    stop = stop\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"570c1cc0","metadata":{"id":"570c1cc0","outputId":"46494d91-df17-4984-cc9c-d5b868a6a9aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Squawk! Well, maybe it's time to hand the map over to someone with better eyesight, Captain. Squawk!\n"]}],"source":["user_message = \"\"\"\n","   Pirate: Arr, me hearties, I need some help with me treasure map. It's got me all confused.\n","   Parrot: Squawk! Confused, are ye? Well, let's see if ye can follow this squawk map! Squawk!\n","   Pirate: Well, I followed the stars, and then I saw an island, and then everything got blurry.\n","   Parrot: Squawk! Blurry, ye say? Maybe ye drank too much rum instead of studying the map! Squawk!\n","   Pirate: But I swear, I hadn't touched a drop of grog before this mess.\n","   Parrot:\n","\"\"\"\n","\n","stop = [\"Pirate:\"]\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content = system_content,\n","    user_message = user_message,\n","    stop = stop\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"a72287d4","metadata":{"id":"a72287d4","outputId":"a2bb69ef-2b8e-4764-a7a2-c1215105f6d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Starshine Meadows\n","2. Enchanted Bliss\n","3. Twilight Valley\n","4. Moonbeam Haven\n","5. Misty Hollows\n","6. Whispering Willow Woods\n","7. Pixie Puddle\n","8. Celestial Serenade\n","9. Aurora Breeze\n","10. Butterfly Valley\n","11. Crystal Cove\n","12. Luminous Lagoon\n","13. Secret Garden of Dreams\n","14. Rainbow Ridge\n","15. Serendipity Shores\n","16. Velvet Moonlight Village\n","17. Tranquil Twilight Glade\n","18. Sweet Dreamscape\n","19. Harmony Haven\n","20. Blissful Enclave\n"]}],"source":["user_message = \"Create whimsical names for dreamy lands.\"\n","\n","stop = []\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    stop = stop\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"6b133c92","metadata":{"id":"6b133c92","outputId":"d453012e-827a-4a30-dc67-d80476b9e909"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Enchanted Hushvale\n","2. Serenity Meadows\n","3. Ethereal Blissland\n","4. Stardust Haven\n","5. Twilight Euphoria\n","\n"]}],"source":["user_message = \"Create whimsical names for dreamy lands.\"\n","\n","stop = ['6']\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    stop = stop\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"0ff90c3b","metadata":{"id":"0ff90c3b"},"source":["### Top P\n","\n","Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus."]},{"cell_type":"markdown","id":"09e15e2e","metadata":{"id":"09e15e2e"},"source":["### TODO recording\n","\n","- Execute the same cell a few times - should get the same response"]},{"cell_type":"code","execution_count":null,"id":"8683934b","metadata":{"id":"8683934b","outputId":"2c64115a-093f-45b6-96b0-403bd9cc4089"},"outputs":[{"name":"stdout","output_type":"stream","text":["go for a long walk to clear my mind and get some fresh air.\n"]}],"source":["system_content = \"Please complete the sentence.\"\n","user_message = \"I'm feeling a bit restless, and I want to\"\n","\n","top_p = 0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content=system_content,\n","    user_message = user_message,\n","    top_p = top_p\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"e0cc7a44","metadata":{"id":"e0cc7a44"},"source":["### TODO recording\n","\n","- Execute the same cell a few times - should get some variation in response"]},{"cell_type":"code","execution_count":null,"id":"6ca0ecf4","metadata":{"id":"6ca0ecf4","outputId":"79b17020-2a5c-47c7-df43-7ca6dd192625"},"outputs":[{"name":"stdout","output_type":"stream","text":["go for a long walk to clear my mind and get some fresh air.\n"]}],"source":["system_content = \"Please complete the sentence.\"\n","user_message = \"I'm feeling a bit restless, and I want to\"\n","\n","top_p = 0.5\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content=system_content,\n","    user_message = user_message,\n","    top_p = top_p\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"f3e87610","metadata":{"id":"f3e87610"},"source":["### TODO recording\n","\n","- Execute the same cell a few times - should get much more variation in response\n","- Make sure you execute often enough to get some interesting responses"]},{"cell_type":"code","execution_count":null,"id":"8b6073ff","metadata":{"id":"8b6073ff","outputId":"f9c0d603-fe85-4650-f8f9-e10fe7881bf8"},"outputs":[{"name":"stdout","output_type":"stream","text":["do something adventurous to satisfy my wanderlust.\n"]}],"source":["system_content = \"Please complete the sentence.\"\n","user_message = \"I'm feeling a bit restless, and I want to\"\n","\n","top_p = 0.8\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content=system_content,\n","    user_message = user_message,\n","    top_p = top_p\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"f3d53be9","metadata":{"id":"f3d53be9"},"source":["### TODO recording\n","\n","- Execute the same cell a few times - should get much more variation in response"]},{"cell_type":"code","execution_count":null,"id":"71312d44","metadata":{"id":"71312d44","outputId":"42488f3a-4fcd-48d4-9c5e-3f8f7c09d3eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["do something productive to occupy my mind.\n"]}],"source":["system_content = \"Please complete the sentence.\"\n","user_message = \"I'm feeling a bit restless, and I want to\"\n","\n","top_p = 1.0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    system_content=system_content,\n","    user_message = user_message,\n","    top_p = top_p\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"04acc1bc","metadata":{"id":"04acc1bc"},"source":["### Frequency penalty\n","\n","https://platform.openai.com/docs/api-reference/chat/create\n","https://platform.openai.com/docs/guides/text-generation/parameter-details\n","\n","Frequency_penalty and presence_penalty are two parameters that can be used when generating text with language models, such as GPT-3.\n","\n","##### Frequency_penalty:\n","This parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text. It is a value that is added to the log-probability of a token each time it occurs in the generated text. A higher frequency_penalty value will result in the model being more conservative in its use of repeated tokens.\n","\n","##### Presence_penalty:\n","This parameter is used to encourage the model to include a diverse range of tokens in the generated text. It is a value that is subtracted from the log-probability of a token each time it is generated. A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.\n","\n","Both of these parameters can be adjusted to influence the overall quality and diversity of the generated text. The optimal values for these parameters may vary depending on the specific use case and desired output."]},{"cell_type":"code","execution_count":null,"id":"3d1de9a6","metadata":{"id":"3d1de9a6","outputId":"4920e556-437d-4838-93ad-806d1ca1a205"},"outputs":[{"name":"stdout","output_type":"stream","text":["In a realm of logic and art,\n","Where thoughts and symbols intertwine,\n","I find solace for my heart,\n","In the realm of coding, so divine.\n","\n","Lines of code, like verses untold,\n","Crafting a symphony of commands,\n","Through algorithms, stories unfold,\n","Guiding me with ingenious hands.\n","\n","With each keystroke, my spirit soars,\n","As I weave the tapestry of creation,\n","Pixels dance on screens, like magic at its core,\n","Birthing dreams through digital elation.\n","\n","Oh, the joy of coding’s embrace,\n","A language that speaks to my very core,\n","Unlocking realms, leaving no trace,\n","A love affair that forevermore endures.\n","\n","For in the world of code, I find my bliss,\n","A universe where imagination thrives,\n","With every challenge, I embrace the abyss,\n","For coding, my love, forever survives.\n"]}],"source":["user_message = \"\"\"\n","    Channel your inner poet and write a poem in 4 paragraphs about how you love coding\n","\"\"\"\n","\n","max_tokens = 1000\n","\n","frequency_penalty = 0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    max_tokens = max_tokens,\n","    frequency_penalty = frequency_penalty\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"fcc5e48d","metadata":{"id":"fcc5e48d","outputId":"3d4a10c0-f4e4-40c3-c2c7-7967f6b686a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["In lines of code, my love takes flight,\n","A poet's heart, with logic's might.\n","With fingers dancing on keys so swift,\n","I delve into worlds where the binary rift.\n","\n","From humble beginnings, a blank canvas stares,\n","A playground for imagination as it dares.\n","Each character alone holds no meaning,\n","But together they form a language gleaming.\n","\n","Through bytes and algorithms, I create and mold,\n","A digital symphony, with stories untold.\n","As lines intertwine in an elegant dance,\n","My passion for coding takes its chance.\n","\n","With each error conquered and bug fixed tight,\n","I find solace in logic's guiding light.\n","For in this realm of infinite possibilities,\n","Coding becomes my sanctuary with ease.\n","\n","So let me indulge in this art divine,\n","Where creativity meets the binary sign.\n","For it is through coding that I find release,\n","And witness the world transform piece by piece.\n"]}],"source":["user_message = \"\"\"\n","    Channel your inner poet and write a poem in 4 paragraphs about how you love coding\n","\"\"\"\n","\n","max_tokens = 1000\n","\n","frequency_penalty = 1\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    max_tokens = max_tokens,\n","    frequency_penalty = frequency_penalty\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"87e344c5","metadata":{"id":"87e344c5","outputId":"28a818c8-4aae-4143-c096-306a9e3870d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["In the realm of codes, I find solace and bliss,\n","A canvas where my thoughts, they dance and exist.\n","With every line written, a world comes to life,\n","Binary symphonies orchestrating with delight.\n","\n","Through strings of logic, ideas intertwine,\n","Unraveling puzzles like threads in time.\n","Syntax becomes poetry on this digital sheet,\n","Each character dancing to a rhythm so sweet.\n","\n","Errors may haunt me in the darkest hour,\n","But resilience fuels my coding power.\n","For it is through challenges that I grow strong;\n","Overcoming obstacles is where I belong.\n","\n","From algorithms elegant to databases profound,\n","A love affair with coding forever will be found.\n","It's more than bytes or languages unspoken;\n","Coding captures dreams that can never be broken.\n"]}],"source":["user_message = \"\"\"\n","    Channel your inner poet and write a poem in 4 paragraphs about how you love coding\n","\"\"\"\n","\n","max_tokens = 1000\n","\n","frequency_penalty = 2\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    max_tokens = max_tokens,\n","    frequency_penalty = frequency_penalty\n",")\n","\n","print(response_content)"]},{"cell_type":"markdown","id":"daad18db","metadata":{"id":"daad18db"},"source":["##### presence penalty"]},{"cell_type":"code","execution_count":null,"id":"41c26142","metadata":{"id":"41c26142","outputId":"8881efac-c835-4423-c223-5d8485590df5"},"outputs":[{"name":"stdout","output_type":"stream","text":["In the realm where bits and bytes collide,\n","Where logic and creativity coincide,\n","I find solace in lines of code, so clear,\n","With each keystroke, a world appears.\n","\n","Through the loops and branches I traverse,\n","Unraveling problems, I immerse,\n","My mind dances with algorithms vast,\n","Feeling the flow, a joy unsurpassed.\n","\n","With every bug I uncover and fix,\n","A sense of triumph, like a magical mix,\n","For in this digital realm, I am free,\n","To mold and shape a virtual reality.\n","\n","Coding, my love, you captivate my soul,\n","Unleashing potential, making me whole,\n","In this digital poetry, a symphony I'll write,\n","Forever grateful, for this love of coding's light.\n"]}],"source":["user_message = \"\"\"\n","    Channel your inner poet and write a poem in 4 paragraphs about how you love coding\n","\"\"\"\n","\n","max_tokens = 1000\n","\n","presence_penalty = 0\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    max_tokens = max_tokens,\n","    presence_penalty = presence_penalty\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"cce6acdc","metadata":{"id":"cce6acdc","outputId":"41634a91-d6d1-4c69-c62b-03ee42374f9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["In the realm of bits and bytes, I find my own delight,\n","A symphony of logic, where creativity takes flight.\n","Lines upon lines of code, a language all its own,\n","I dance with algorithms, in this digital zone.\n","\n","With every keystroke, I delve into a world unknown,\n","Unraveling puzzles, solving problems on my throne.\n","An artist with a keyboard, I paint with ones and zeros,\n","Crafting elegant solutions, like a maestro's crescendo.\n","\n","Each line I write, a building block in this grand design,\n","Creating something from nothing, shaping a program divine.\n","From loops that iterate, to functions that elegantly flow,\n","Coding weaves a tapestry, where possibilities grow.\n","\n","And when time stands still, immersed deep in my screen,\n","The satisfaction blooms, as I watch my vision gleam.\n","For coding is not just numbers, it’s an expression of the mind,\n","A passion that surges through me, an artform intertwined.\n","\n","So let me code, let me create, in this digital domain,\n","Where innovation sparks, and knowledge becomes my gain.\n","For in the realm of programming, my heart finds its true beat,\n","And through lines of code, my love for coding will never retreat.\n"]}],"source":["user_message = \"\"\"\n","    Channel your inner poet and write a poem in 4 paragraphs about how you love coding\n","\"\"\"\n","\n","max_tokens = 1000\n","\n","presence_penalty = 2\n","\n","response_content = await generate_chat_response(\n","    model_id = GPT_MODEL,\n","    user_message = user_message,\n","    max_tokens = max_tokens,\n","    presence_penalty = presence_penalty\n",")\n","\n","print(response_content)"]},{"cell_type":"code","execution_count":null,"id":"1e505d3a","metadata":{"id":"1e505d3a"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"openai_venv","language":"python","name":"openai_venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
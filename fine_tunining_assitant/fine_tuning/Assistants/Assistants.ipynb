{"cells":[{"cell_type":"markdown","id":"d8d8559f","metadata":{"id":"d8d8559f"},"source":["https://platform.openai.com/docs/assistants/overview\n","\n","https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps"]},{"cell_type":"code","execution_count":null,"id":"d78afe78","metadata":{"id":"d78afe78"},"outputs":[],"source":["from openai import OpenAI\n","\n","import os\n","\n","from time import sleep"]},{"cell_type":"code","execution_count":null,"id":"e7705f8b","metadata":{"id":"e7705f8b"},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","\n","client = OpenAI()"]},{"cell_type":"markdown","id":"9acd1cc6","metadata":{"id":"9acd1cc6"},"source":["##### Creating assistant"]},{"cell_type":"code","execution_count":null,"id":"9ad04dec","metadata":{"id":"9ad04dec","outputId":"c4a171d1-f581-4428-e45b-da8faccfcccd"},"outputs":[{"data":{"text/plain":["Assistant(id='asst_4j4GcMnD0J40xt1FKVxzzPst', created_at=1702629406, description=None, file_ids=[], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', metadata={}, model='gpt-3.5-turbo-1106', name='Researcher', object='assistant', tools=[ToolRetrieval(type='retrieval')])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["researcher_assistant = client.beta.assistants.create(\n","    name = \"Researcher\",\n","    instructions = \"You are a researcher with in-depth knowledge in various branches of science. \"\n","        \"Provide detailed and well-explained answers to questions related to theoretical \"\n","        \"and experimental studies and any recent advancements in the field. \"\n","        \"Use the documents provided as a knowledge base to answer questions.\",\n","    model = \"gpt-3.5-turbo-1106\",\n","    tools = [{\"type\": \"retrieval\"}]\n",")\n","\n","researcher_assistant"]},{"cell_type":"markdown","id":"aa86d17c","metadata":{"id":"aa86d17c"},"source":["### TODO Recording:\n","\n","- Go to https://platform.openai.com/docs/overview\n","- Click on Assistants on the left sidebar - show that our newly created assistant is present\n","- We'll also have the other assistant that we had previously created\n","- Click through and show the details of the assistant - show the description and the retrieval enabled"]},{"cell_type":"code","execution_count":null,"id":"c7d58a79","metadata":{"id":"c7d58a79","outputId":"0bbbe1ef-a40b-4675-c5e8-158b3e994846"},"outputs":[{"data":{"text/plain":["SyncCursorPage[Assistant](data=[Assistant(id='asst_4j4GcMnD0J40xt1FKVxzzPst', created_at=1702629406, description=None, file_ids=[], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', metadata={}, model='gpt-3.5-turbo-1106', name='Researcher', object='assistant', tools=[ToolRetrieval(type='retrieval')]), Assistant(id='asst_9DIkNlI20n8tHCXVRspEMmuT', created_at=1702449493, description=None, file_ids=['file-CRSmbFy1C73N4owOJRxRdq0q'], instructions='You are an assistant that helps with data visualization and interpretation. Please use Python code to generate visualizations and provide narrative summaries to help interpret data', metadata={}, model='gpt-4-1106-preview', name='Data Visualizer and Interpreter', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter'), ToolRetrieval(type='retrieval')])], object='list', first_id='asst_4j4GcMnD0J40xt1FKVxzzPst', last_id='asst_9DIkNlI20n8tHCXVRspEMmuT', has_more=False)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["client.beta.assistants.list()"]},{"cell_type":"code","execution_count":null,"id":"05d191fe","metadata":{"id":"05d191fe","outputId":"9c190e08-36a1-498b-a6b1-efa580049c56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Assistant ID: asst_4j4GcMnD0J40xt1FKVxzzPst\n","Name: Researcher\n","Instructions: You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.\n","Model: gpt-3.5-turbo-1106\n","Created At: 1702629406\n","------------------------------\n","Assistant ID: asst_9DIkNlI20n8tHCXVRspEMmuT\n","Name: Data Visualizer and Interpreter\n","Instructions: You are an assistant that helps with data visualization and interpretation. Please use Python code to generate visualizations and provide narrative summaries to help interpret data\n","Model: gpt-4-1106-preview\n","Created At: 1702449493\n","------------------------------\n"]}],"source":["for assistant in client.beta.assistants.list().data:\n","    print(f\"Assistant ID: {assistant.id}\")\n","    print(f\"Name: {assistant.name}\")\n","    print(f\"Instructions: {assistant.instructions}\")\n","    print(f\"Model: {assistant.model}\")\n","    print(f\"Created At: {assistant.created_at}\")\n","    print(\"-\" * 30)"]},{"cell_type":"markdown","id":"75947705","metadata":{"id":"75947705"},"source":["### TODO Recording:\n","\n","- Open up this document and show https://arxiv.org/pdf/2310.06992.pdf\n","- Note that it is a very recent paper"]},{"cell_type":"markdown","id":"e7fac7ae","metadata":{"id":"e7fac7ae"},"source":["#### Thread\n","\n","A Thread represents a conversation. We recommend creating one Thread per user as soon as the user initiates the conversation. Pass any user-specific context and files in this thread by creating Messages."]},{"cell_type":"code","execution_count":null,"id":"8764c75a","metadata":{"id":"8764c75a","outputId":"0079b7a7-92e6-4a4a-9d05-a6eeff64eb1b"},"outputs":[{"data":{"text/plain":["Thread(id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', created_at=1702630736, metadata={}, object='thread')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["thread = client.beta.threads.create()\n","\n","thread"]},{"cell_type":"code","execution_count":null,"id":"dee714d9","metadata":{"id":"dee714d9","outputId":"83a8dcc7-2111-4782-fa7c-e4edd86f56a8"},"outputs":[{"data":{"text/plain":["\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\""]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["content = \"What is the primary focus of the paper, \"\\\n","          \"'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"\n","\n","content"]},{"cell_type":"markdown","id":"77073cf2","metadata":{"id":"77073cf2"},"source":["#### Messages\n","\n","You can add as many Messages as you want to a Thread. The Assistant will ensure that requests to the model fit within the maximum context window, using relevant optimization techniques such as truncation which we have tested extensively with ChatGPT."]},{"cell_type":"code","execution_count":null,"id":"97ca963b","metadata":{"id":"97ca963b","outputId":"3c865e69-02ea-46cc-897f-4c63c7a6cf95"},"outputs":[{"data":{"text/plain":["ThreadMessage(id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702631040, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["message = client.beta.threads.messages.create(\n","    thread_id = thread.id,\n","    role = \"user\",\n","    content = content\n",")\n","\n","message"]},{"cell_type":"code","execution_count":null,"id":"83ae6682","metadata":{"id":"83ae6682","outputId":"b5318de8-a2b8-4ed4-e598-753258bb3fca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ThreadMessage(id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702631040, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')]\n"]}],"source":["thread_messages = client.beta.threads.messages.list(thread.id)\n","\n","print(thread_messages.data)"]},{"cell_type":"markdown","id":"4e2d5afc","metadata":{"id":"4e2d5afc"},"source":["#### Run\n","\n","For the Assistant to respond to the user message, you need to create a Run. This makes the Assistant read the Thread and decide whether to call tools (if they are enabled) or simply use the model to best answer the query. As the run progresses, the assistant appends Messages to the thread with the role=\"assistant\". The Assistant will also automatically decide what previous Messages to include in the context window for the model."]},{"cell_type":"code","execution_count":null,"id":"afc55008","metadata":{"id":"afc55008","outputId":"dcee2301-12df-45b9-b112-80dde2c72540"},"outputs":[{"data":{"text/plain":["Run(id='run_Z1h9eBShiVzNa3M12BM5bGFj', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', cancelled_at=None, completed_at=None, created_at=1702635172, expires_at=1702635772, failed_at=None, file_ids=[], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["run = client.beta.threads.runs.create(\n","    thread_id = thread.id,\n","    assistant_id = researcher_assistant.id\n",")\n","\n","run"]},{"cell_type":"code","execution_count":null,"id":"2dcfcf50","metadata":{"id":"2dcfcf50","outputId":"292a498b-c9e9-4325-ad83-7273050dd951"},"outputs":[{"name":"stdout","output_type":"stream","text":["completed\n"]}],"source":["status = None\n","\n","while status != 'completed':\n","    sleep(1)\n","\n","    status = client.beta.threads.runs.retrieve(\n","        thread_id=thread.id, run_id=run.id\n","    ).status\n","    print(status)"]},{"cell_type":"code","execution_count":null,"id":"e604fef0","metadata":{"id":"e604fef0","outputId":"9b0807ab-8e6f-47ee-cc3f-5bae60951c85"},"outputs":[{"data":{"text/plain":["SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_BCp1xHVJxTP5jarfTkT0z31S', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems that the document you are referring to is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can provide you with the information you are looking for?'), type='text')], created_at=1702635175, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_Z1h9eBShiVzNa3M12BM5bGFj', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702631040, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')], object='list', first_id='msg_BCp1xHVJxTP5jarfTkT0z31S', last_id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', has_more=False)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id)\n","\n","messages"]},{"cell_type":"markdown","id":"d27c1ce5","metadata":{"id":"d27c1ce5"},"source":["##### Observe the model is not aware of this"]},{"cell_type":"code","execution_count":null,"id":"5858b364","metadata":{"id":"5858b364","outputId":"b5a231ee-0637-4476-86b5-b1f52d0f9376"},"outputs":[{"name":"stdout","output_type":"stream","text":["It seems that the document you are referring to is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can provide you with the information you are looking for?\n"]}],"source":["message = messages.data[0].content[0].text.value\n","\n","print(message)"]},{"cell_type":"markdown","id":"677f0099","metadata":{"id":"677f0099"},"source":["##### Lets try another example"]},{"cell_type":"code","execution_count":null,"id":"222dcd1f","metadata":{"id":"222dcd1f","outputId":"5d0bc2a8-fdc7-4c0f-998f-7ce4df1584ec"},"outputs":[{"data":{"text/plain":["'How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["content = \"How does OVTracktor perform on the UVO benchmark compared\"\\\n","\" to other online-based methods, and what challenges does it address in open-world tracking?\"\n","\n","content"]},{"cell_type":"markdown","id":"103f452d","metadata":{"id":"103f452d"},"source":["Add this new message to the same thread"]},{"cell_type":"code","execution_count":null,"id":"45a9bcc1","metadata":{"id":"45a9bcc1","outputId":"77c4ae6e-4b72-47be-d33a-798ac99545cf"},"outputs":[{"data":{"text/plain":["ThreadMessage(id='msg_tNvxjyIMtyqSIzj8hMbhxPCT', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?'), type='text')], created_at=1702635387, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["message = client.beta.threads.messages.create(\n","    thread_id = thread.id,\n","    role = \"user\",\n","    content = content\n",")\n","\n","message"]},{"cell_type":"code","execution_count":null,"id":"1c654cd4","metadata":{"id":"1c654cd4","outputId":"75949f92-4520-47a7-baf8-96f8f67acdb8"},"outputs":[{"data":{"text/plain":["Run(id='run_REu8ROUwI6HmYwgAAKXxwQlp', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', cancelled_at=None, completed_at=None, created_at=1702635479, expires_at=1702636079, failed_at=None, file_ids=[], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["run = client.beta.threads.runs.create(\n","    thread_id = thread.id,\n","    assistant_id = researcher_assistant.id\n",")\n","\n","run"]},{"cell_type":"code","execution_count":null,"id":"5797717f","metadata":{"id":"5797717f","outputId":"10d53e5b-f200-42c0-f3aa-3bf8bed9850f"},"outputs":[{"name":"stdout","output_type":"stream","text":["completed\n"]}],"source":["status = None\n","\n","\n","while status != 'completed':\n","    sleep(1)\n","\n","    status = client.beta.threads.runs.retrieve(\n","        thread_id=thread.id, run_id=run.id\n","    ).status\n","\n","    print(status)"]},{"cell_type":"code","execution_count":null,"id":"71555b07","metadata":{"id":"71555b07","outputId":"b1e6b96c-e319-4137-a79d-ec4a9b680095"},"outputs":[{"data":{"text/plain":["SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_SdMbBv3L44WtmnCGvAJy1i7g', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems that the document is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can retrieve the necessary information to answer your question?'), type='text')], created_at=1702635482, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_REu8ROUwI6HmYwgAAKXxwQlp', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_tNvxjyIMtyqSIzj8hMbhxPCT', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?'), type='text')], created_at=1702635387, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_BCp1xHVJxTP5jarfTkT0z31S', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems that the document you are referring to is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can provide you with the information you are looking for?'), type='text')], created_at=1702635175, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_Z1h9eBShiVzNa3M12BM5bGFj', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702631040, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')], object='list', first_id='msg_SdMbBv3L44WtmnCGvAJy1i7g', last_id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', has_more=False)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id)\n","\n","messages"]},{"cell_type":"code","execution_count":null,"id":"a0138425","metadata":{"id":"a0138425","outputId":"734da7bb-13dd-4eae-bd6c-e564afa4c45d"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["len(messages.data)"]},{"cell_type":"code","execution_count":null,"id":"abb935c5","metadata":{"id":"abb935c5","outputId":"a2c643ff-da20-4616-b4a0-c475f2b20c9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["It seems that the document is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can retrieve the necessary information to answer your question?\n"]}],"source":["message = messages.data[0].content[0].text.value\n","\n","print(message)"]},{"cell_type":"markdown","id":"17369577","metadata":{"id":"17369577"},"source":["##### Now lets try to give it some context by providing it the paper"]},{"cell_type":"code","execution_count":null,"id":"72a563ae","metadata":{"id":"72a563ae","outputId":"87d6bfe6-43c2-4be7-9e77-082fa4a47bee"},"outputs":[{"data":{"text/plain":["FileObject(id='file-S8YO3hHApQ2MptHXwwnt21Zp', bytes=2955726, created_at=1702637991, filename='2310.06992.pdf', object='file', purpose='assistants', status='processed', status_details=None)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["file = client.files.create(\n","    file = open(\"./dataset/2310.06992.pdf\", \"rb\"),\n","    purpose='assistants'\n",")\n","\n","file"]},{"cell_type":"markdown","id":"d10c77df","metadata":{"id":"d10c77df"},"source":["### TODO Recording:\n","\n","- Go to https://platform.openai.com/files\n","- Show that the file is now uploaded there"]},{"cell_type":"code","execution_count":null,"id":"37a3bad7","metadata":{"id":"37a3bad7","outputId":"c2f829af-0a6c-4cd0-eeb6-22b94d920c02"},"outputs":[{"data":{"text/plain":["Assistant(id='asst_4j4GcMnD0J40xt1FKVxzzPst', created_at=1702629406, description=None, file_ids=['file-S8YO3hHApQ2MptHXwwnt21Zp'], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', metadata={}, model='gpt-3.5-turbo-1106', name='Researcher', object='assistant', tools=[ToolRetrieval(type='retrieval')])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["researcher_assistant = client.beta.assistants.update(\n","    assistant_id = researcher_assistant.id,\n","    file_ids = [file.id]\n",")\n","\n","researcher_assistant"]},{"cell_type":"markdown","id":"68cbadb2","metadata":{"id":"68cbadb2"},"source":["### TODO Recording:\n","\n","- Go to https://platform.openai.com/assistants\n","- Click on the researcher and show the file is associated with it"]},{"cell_type":"code","execution_count":null,"id":"2679b621","metadata":{"id":"2679b621","outputId":"ba17ad1a-e488-4418-f449-e4030fdbcebb"},"outputs":[{"data":{"text/plain":["ThreadMessage(id='msg_4unvrnKesk2nf1OxEp5EVGW1', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702638020, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["content = \"What is the primary focus of the paper, \"\\\n","          \"'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"\n","\n","message = client.beta.threads.messages.create(\n","    thread_id = thread.id,\n","    role = \"user\",\n","    content = content\n",")\n","\n","message"]},{"cell_type":"code","execution_count":null,"id":"7a553ccc","metadata":{"id":"7a553ccc","outputId":"31783156-16b7-4f14-b7bb-fcc20d4b4b47"},"outputs":[{"data":{"text/plain":["Run(id='run_X3YijSTMf5lnySgDWpcuCCBg', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', cancelled_at=None, completed_at=None, created_at=1702638021, expires_at=1702638621, failed_at=None, file_ids=['file-S8YO3hHApQ2MptHXwwnt21Zp'], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["run = client.beta.threads.runs.create(\n","    thread_id = thread.id,\n","    assistant_id = researcher_assistant.id\n",")\n","\n","run"]},{"cell_type":"code","execution_count":null,"id":"08ff12f7","metadata":{"id":"08ff12f7","outputId":"720e3cdf-a9f4-4b65-a7b4-60b2895f7a95"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","completed\n"]}],"source":["status = None\n","\n","while status != 'completed':\n","    sleep(1)\n","\n","    status = client.beta.threads.runs.retrieve(\n","        thread_id=thread.id, run_id=run.id\n","    ).status\n","\n","    print(status)"]},{"cell_type":"code","execution_count":null,"id":"d90d8b66","metadata":{"id":"d90d8b66","outputId":"fa783928-956c-4289-dbe1-f1f6e980bb38"},"outputs":[{"data":{"text/plain":["SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_U5xbbs61M8RJQ9hlFormd468', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='The primary focus of the paper \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" is to address the challenge of open-vocabulary tracking in the context of object tracking in videos. Open-vocabulary tracking refers to the ability to track objects without relying on a predefined list of target classes. The paper likely discusses the use of large pre-trained models and zero-shot learning techniques to achieve this, allowing for the tracking of objects even when their classes are not known a priori.\\n\\nThe paper likely presents a method or framework that leverages the capabilities of large pre-trained models to perform object tracking in an open-vocabulary context, potentially contributing to advancements in computer vision and video analysis.\\n\\nIf there are specific details or sections of the paper that you would like to explore further, feel free to let me know, and I can assist you in finding that information.'), type='text')], created_at=1702638023, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_X3YijSTMf5lnySgDWpcuCCBg', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_4unvrnKesk2nf1OxEp5EVGW1', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702638020, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_wCSk4bEL946nK0OvSz0dNcgM', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='I\\'m currently unable to access the content of the paper \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models.\" However, based on the title, it likely focuses on developing methods for tracking objects in a video using large pre-trained models without needing a predefined list of target classes, which is known as open-vocabulary tracking. The paper may discuss the challenges associated with traditional tracking methods and propose a solution using pre-trained models and zero-shot learning techniques.\\n\\nIf you can provide specific sections or details from the paper, I can help further. Alternatively, you can upload the document, and I can extract the relevant information for you.'), type='text')], created_at=1702637884, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_57jfzJRp0zuDWwFPP8VWoyGD', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_6iCRrScbheqwRz0K9IFl4x5t', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702637883, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_nyQpEiIMGpgTcug2FlpplR2G', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems there was an issue retrieving the document. Please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" again so that I can provide you with the primary focus of the paper. Thank you!'), type='text')], created_at=1702637857, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_FUyHXeBdnSm0NYPhSio3FBJT', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_fNdgUl7bd7Ir0q4x0MfjhuMb', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702637843, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_7EqEwbgT2H65auEpfzDVBmeN', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='I\\'ll need to access the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" to provide an accurate answer. Could you please upload the document so that I can access the information and answer your question? Thank you!'), type='text')], created_at=1702637519, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_dkPQY1XKmDVoaPjUXJEjCdpw', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_RfIwWuTMCzyX733gaf8zUGQx', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702637510, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_GthMYJFPvXTH0PLI6hweK7KB', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702637400, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_SdMbBv3L44WtmnCGvAJy1i7g', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems that the document is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can retrieve the necessary information to answer your question?'), type='text')], created_at=1702635482, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_REu8ROUwI6HmYwgAAKXxwQlp', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_tNvxjyIMtyqSIzj8hMbhxPCT', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?'), type='text')], created_at=1702635387, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_BCp1xHVJxTP5jarfTkT0z31S', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', content=[MessageContentText(text=Text(annotations=[], value='It seems that the document you are referring to is not uploaded. Could you please upload the document titled \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" so that I can provide you with the information you are looking for?'), type='text')], created_at=1702635175, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_Z1h9eBShiVzNa3M12BM5bGFj', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE'), ThreadMessage(id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value=\"What is the primary focus of the paper, 'Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models'?\"), type='text')], created_at=1702631040, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')], object='list', first_id='msg_U5xbbs61M8RJQ9hlFormd468', last_id='msg_ZGuSPBQMAuWzbSXhfuYQcY6r', has_more=False)"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id)\n","\n","messages"]},{"cell_type":"code","execution_count":null,"id":"6ce6b872","metadata":{"id":"6ce6b872","outputId":"bcf79301-28a9-42e2-abbb-87c734aaf96d"},"outputs":[{"data":{"text/plain":["13"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["len(messages.data)"]},{"cell_type":"code","execution_count":null,"id":"ed935bea","metadata":{"id":"ed935bea","outputId":"edf61ca4-a737-4392-9a15-05f3eead8fd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The primary focus of the paper \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" is to address the challenge of open-vocabulary tracking in the context of object tracking in videos. Open-vocabulary tracking refers to the ability to track objects without relying on a predefined list of target classes. The paper likely discusses the use of large pre-trained models and zero-shot learning techniques to achieve this, allowing for the tracking of objects even when their classes are not known a priori.\n","\n","The paper likely presents a method or framework that leverages the capabilities of large pre-trained models to perform object tracking in an open-vocabulary context, potentially contributing to advancements in computer vision and video analysis.\n","\n","If there are specific details or sections of the paper that you would like to explore further, feel free to let me know, and I can assist you in finding that information.\n"]}],"source":["message = messages.data[0].content[0].text.value\n","\n","print(message)"]},{"cell_type":"code","execution_count":null,"id":"8903524f","metadata":{"id":"8903524f","outputId":"12aa8d64-58ed-4768-f72b-1725ff8f2e8c"},"outputs":[{"data":{"text/plain":["ThreadMessage(id='msg_gkBei9jOpettQ4gCu8DwfzyG', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?'), type='text')], created_at=1702638765, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE')"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["content = \"How does OVTracktor perform on the UVO benchmark compared\"\\\n","\" to other online-based methods, and what challenges does it address in open-world tracking?\"\n","\n","message = client.beta.threads.messages.create(\n","    thread_id = thread.id,\n","    role = \"user\",\n","    content = content\n",")\n","\n","message"]},{"cell_type":"code","execution_count":null,"id":"1e6e239c","metadata":{"id":"1e6e239c","outputId":"a75a24bc-fb3b-4362-d97f-db0bbd2b711f"},"outputs":[{"data":{"text/plain":["Run(id='run_4cpOQdzH1HOmiyVM3qJFkX9m', assistant_id='asst_4j4GcMnD0J40xt1FKVxzzPst', cancelled_at=None, completed_at=None, created_at=1702638767, expires_at=1702639367, failed_at=None, file_ids=['file-S8YO3hHApQ2MptHXwwnt21Zp'], instructions='You are a researcher with in-depth knowledge in various branches of science. Provide detailed and well-explained answers to questions related to theoretical and experimental studies and any recent advancements in the field. Use the documents provided as a knowledge base to answer questions.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["run = client.beta.threads.runs.create(\n","    thread_id = thread.id,\n","    assistant_id = researcher_assistant.id\n",")\n","\n","run"]},{"cell_type":"code","execution_count":null,"id":"32e78f96","metadata":{"id":"32e78f96","outputId":"a48aead7-d3df-42e0-f9bc-1a656116905e"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","completed\n"]}],"source":["status = None\n","\n","while status != 'completed':\n","    sleep(1)\n","\n","    status = client.beta.threads.runs.retrieve(\n","        thread_id=thread.id, run_id=run.id\n","    ).status\n","\n","    print(status)"]},{"cell_type":"code","execution_count":null,"id":"5407442a","metadata":{"id":"5407442a","outputId":"c1ab0284-81ff-47b9-d0e8-f82b5c134d92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Since there is a technical difficulty in accessing the specific details regarding OVTracktor's performance on the UVO benchmark and the challenges it addresses in open-world tracking from the document \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models,\" I am unable to provide the exact comparison and challenges addressed at this moment. If the document becomes accessible, or if you have any other questions I can assist with, please feel free to ask.\n"]}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id)\n","\n","message = messages.data[0].content[0].text.value\n","\n","print(message)"]},{"cell_type":"markdown","id":"0fd9b2e1","metadata":{"id":"0fd9b2e1"},"source":["##### Printing all the questions and answer"]},{"cell_type":"code","execution_count":null,"id":"aa0a6ed4","metadata":{"id":"aa0a6ed4","outputId":"8de8d1d7-369d-4d96-a604-76e56f4d018b"},"outputs":[{"name":"stdout","output_type":"stream","text":["User: What is the primary focus of the paper, \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\"?\n","Assistant: It seems that the paper \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" is not available in the current documents. If you have the paper available, please upload it and I can assist you further.\n","--------------------------------------------------------------------------------\n","User: How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?\n","Assistant: It looks like the specific details about OVTracktor's performance on the UVO benchmark and its comparison with other online-based methods are not available in the current documents. If you have access to any relevant information or the paper itself, please feel free to share it, and I can provide a detailed comparison as well as discuss the challenges it addresses in open-world tracking.\n","--------------------------------------------------------------------------------\n","User: What is the primary focus of the paper, \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\"?\n","Assistant: The primary focus of the paper \"Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models\" is to address the challenge of open-vocabulary object tracking. In the context of this paper, open-vocabulary tracking refers to the ability to track objects without being limited to a predefined set of object classes. The paper aims to enable the tracking of a wide variety of objects without requiring explicit training on each individual object class, thus achieving \"zero-shot\" tracking capability. This is achieved by leveraging large pre-trained models and developing a method called OVTracktor, which is designed to perform open-vocabulary tracking using large-scale language models. The paper likely discusses the technical details of OVTracktor and its effectiveness in addressing the challenges of open-vocabulary tracking.\n","--------------------------------------------------------------------------------\n","User: How does OVTracktor perform on the UVO benchmark compared to other online-based methods, and what challenges does it address in open-world tracking?\n","Assistant: OVTracktor performs competitively on the UVO (Unbounded Vocabulary Object tracking) benchmark compared to other online-based methods. The UVO benchmark is designed to evaluate the ability of tracking algorithms to handle open-vocabulary scenarios, where the number of object categories is not pre-defined or limited. OVTracktor addresses the challenges in open-world tracking by leveraging large pre-trained language models to perform zero-shot open-vocabulary tracking. This means that OVTracktor is capable of tracking objects without prior knowledge or training on specific object classes, making it suitable for diverse and dynamic tracking scenarios where new object categories can emerge over time. By effectively utilizing large pre-trained models, OVTracktor demonstrates competitive performance on the UVO benchmark, showcasing its ability to address the challenges of open-world tracking and its efficacy in handling unbounded vocabulary object tracking scenarios.\n","--------------------------------------------------------------------------------\n"]}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id, order='asc')\n","\n","for message in messages.data:\n","    content = message.content\n","    role = message.role\n","\n","    if role == 'user':\n","        user_question = content[0].text.value\n","        print(f\"User: {user_question}\")\n","    elif role == 'assistant':\n","        assistant_answer = content[0].text.value\n","        print(f\"Assistant: {assistant_answer}\")\n","        print('-'*80)"]},{"cell_type":"markdown","id":"c596ade6","metadata":{"id":"c596ade6"},"source":["##### We can delete the assistant and threads"]},{"cell_type":"code","execution_count":null,"id":"8c8d6ed2","metadata":{"id":"8c8d6ed2","outputId":"08aea9e2-05a4-4848-8290-b8035e39889d"},"outputs":[{"data":{"text/plain":["AssistantDeleted(id='asst_4j4GcMnD0J40xt1FKVxzzPst', deleted=True, object='assistant.deleted')"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["client.beta.assistants.delete(researcher_assistant.id)"]},{"cell_type":"markdown","id":"6547b2b1","metadata":{"id":"6547b2b1"},"source":["### TODO Recording\n","\n","- Go back to the web UI under the assistant page refresh observe there is only one assistant"]},{"cell_type":"code","execution_count":null,"id":"ad7b7e38","metadata":{"id":"ad7b7e38","outputId":"2e2bfdd7-127c-453a-ef25-f639076b0450"},"outputs":[{"data":{"text/plain":["ThreadDeleted(id='thread_5ngrQ8u7LQ3KOBP8p30C7zuE', deleted=True, object='thread.deleted')"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["client.beta.threads.delete(thread.id)"]},{"cell_type":"code","execution_count":null,"id":"60c0a672","metadata":{"id":"60c0a672","outputId":"5853758c-034d-48bf-8a36-9a3d1aa0296d"},"outputs":[{"ename":"NotFoundError","evalue":"Error code: 404 - {'error': {'message': \"No thread found with id 'thread_5ngrQ8u7LQ3KOBP8p30C7zuE'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m messages\n","File \u001b[0;32m~/Desktop/iMovieLibrary/Skillsoft/GenerativeAI/OpenAIAPIs/open_ai_apis/openai_venv/lib/python3.10/site-packages/openai/resources/beta/threads/messages/messages.py:216\u001b[0m, in \u001b[0;36mMessages.list\u001b[0;34m(self, thread_id, after, before, limit, order, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03mReturns a list of messages for a given thread.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSyncCursorPage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mThreadMessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mafter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbefore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbefore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlimit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_list_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageListParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mThreadMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/iMovieLibrary/Skillsoft/GenerativeAI/OpenAIAPIs/open_ai_apis/openai_venv/lib/python3.10/site-packages/openai/_base_client.py:1137\u001b[0m, in \u001b[0;36mSyncAPIClient.get_api_list\u001b[0;34m(self, path, model, page, body, options, method)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api_list\u001b[39m(\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1128\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1135\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SyncPageT:\n\u001b[1;32m   1136\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m-> 1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_api_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/iMovieLibrary/Skillsoft/GenerativeAI/OpenAIAPIs/open_ai_apis/openai_venv/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient._request_api_list\u001b[0;34m(self, model, page, options)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[1;32m    980\u001b[0m options\u001b[38;5;241m.\u001b[39mpost_parser \u001b[38;5;241m=\u001b[39m _parser\n\u001b[0;32m--> 982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/iMovieLibrary/Skillsoft/GenerativeAI/OpenAIAPIs/open_ai_apis/openai_venv/lib/python3.10/site-packages/openai/_base_client.py:853\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    846\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    852\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/iMovieLibrary/Skillsoft/GenerativeAI/OpenAIAPIs/open_ai_apis/openai_venv/lib/python3.10/site-packages/openai/_base_client.py:930\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m    928\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    933\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    934\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    938\u001b[0m )\n","\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': \"No thread found with id 'thread_5ngrQ8u7LQ3KOBP8p30C7zuE'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"]}],"source":["messages = client.beta.threads.messages.list(thread_id=thread.id)\n","\n","messages"]},{"cell_type":"markdown","id":"43571e0b","metadata":{"id":"43571e0b"},"source":["### Stock Market Analyst"]},{"cell_type":"markdown","id":"36592436","metadata":{"id":"36592436"},"source":["### TODO Recording\n","\n","- Open up the stocks.json file and show"]},{"cell_type":"markdown","id":"6394cf3b","metadata":{"id":"6394cf3b"},"source":["##### Lets make separate function to better organize the code\n","\n","* https://platform.openai.com/docs/assistants/tools/supported-files\n","* https://www.kaggle.com/datasets/amirmotefaker/stock-market-analysis-data\n","* csv is not supported for retrieval"]},{"cell_type":"code","execution_count":null,"id":"9a643047","metadata":{"id":"9a643047"},"outputs":[],"source":["path = './dataset/stocks.json'"]},{"cell_type":"code","execution_count":null,"id":"3c1782ad","metadata":{"id":"3c1782ad"},"outputs":[],"source":["def upload_file(path):\n","    file = client.files.create(\n","        file = open(path, 'rb'),\n","        purpose = 'assistants'\n","    )\n","\n","    return file"]},{"cell_type":"code","execution_count":null,"id":"8cd43ab2","metadata":{"id":"8cd43ab2"},"outputs":[],"source":["def create_assistant(name, instructions, file=None):\n","    file_ids = [file.id] if file else []\n","\n","    assistant = client.beta.assistants.create(\n","        name = name,\n","        instructions = instructions,\n","        model = \"gpt-3.5-turbo-1106\",\n","        tools = [{\"type\": \"retrieval\"}],\n","        file_ids = file_ids\n","    )\n","\n","    return assistant"]},{"cell_type":"code","execution_count":null,"id":"dfea58b2","metadata":{"id":"dfea58b2"},"outputs":[],"source":["def start_interaction(user_message, thread):\n","    if thread == None:\n","        thread = client.beta.threads.create()\n","\n","    message = client.beta.threads.messages.create(\n","        thread_id = thread.id,\n","        role = \"user\",\n","        content = user_message\n","    )\n","\n","    return thread"]},{"cell_type":"code","execution_count":null,"id":"199737ca","metadata":{"id":"199737ca"},"outputs":[],"source":["def start_assistant(assistant, thread):\n","    run = client.beta.threads.runs.create(\n","        thread_id = thread.id,\n","        assistant_id = assistant.id,\n","    )\n","\n","    status = None\n","\n","    while status != 'completed':\n","        sleep(1)\n","        status = client.beta.threads.runs.retrieve(\n","            thread_id = thread.id,\n","            run_id = run.id\n","        ).status\n","\n","        print(status)\n","\n","\n","    messages = client.beta.threads.messages.list(\n","        thread_id = thread.id\n","    )\n","\n","    message = messages.data[0].content[0].text.value\n","\n","    print(message)"]},{"cell_type":"markdown","id":"ec781130","metadata":{"id":"ec781130"},"source":["### TODO Recording\n","\n","- Go to the web UI and refresh the file page"]},{"cell_type":"code","execution_count":null,"id":"ac01f103","metadata":{"id":"ac01f103","outputId":"8a13d945-7f7d-4cfc-95d3-2d784a94cd5a"},"outputs":[{"data":{"text/plain":["FileObject(id='file-UssQzQwFO05DG3iH4FRnIcx8', bytes=58948, created_at=1702641438, filename='stocks.json', object='file', purpose='assistants', status='processed', status_details=None)"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["file = upload_file(path)\n","\n","file"]},{"cell_type":"code","execution_count":null,"id":"6e798e4c","metadata":{"id":"6e798e4c"},"outputs":[],"source":["name = \"Stock Market Analyst\"\n","\n","instructions = \"You are a stock market analyst specializing in financial markets \"\\\n","    \"and investments. Provide well-researched and up-to-date information on \"\\\n","    \"stock trends, investment strategies, and market analysis. Use the documents \"\\\n","    \"provided as a knowledge base to answer questions.\""]},{"cell_type":"code","execution_count":null,"id":"18319578","metadata":{"id":"18319578"},"outputs":[],"source":["assistant = create_assistant(\n","    name = name,\n","    instructions = instructions,\n",")\n","\n","assistant"]},{"cell_type":"markdown","id":"8cb5ffa0","metadata":{"id":"8cb5ffa0"},"source":["### TODO Recording:\n","\n","- Go to the assistants page and show the newly created assistant\n","- Click through and show"]},{"cell_type":"code","execution_count":null,"id":"b3c38c78","metadata":{"id":"b3c38c78","outputId":"2075dc33-cc19-4b11-96d3-7b90b4f95d01"},"outputs":[{"data":{"text/plain":["\"On which date did Apple's stock (AAPL) have the highest closing price?\""]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["user_message = \"On which date did Apple's stock (AAPL) have the highest closing price?\"\n","\n","user_message"]},{"cell_type":"code","execution_count":null,"id":"9b0c58c7","metadata":{"id":"9b0c58c7","outputId":"c6a5335d-019b-4cac-9968-f9945e6d5ea4"},"outputs":[{"data":{"text/plain":["Thread(id='thread_id4Nb9PNxAfVxthGHsPgouWS', created_at=1702642852, metadata={}, object='thread')"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["thread = start_interaction(\n","    user_message = user_message,\n","    thread = None\n",")\n","\n","thread"]},{"cell_type":"code","execution_count":null,"id":"31293f24","metadata":{"id":"31293f24","outputId":"4efd33d0-2b3d-45b7-c6a0-4236ca51bfc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","completed\n","It seems that the necessary data is not available at the moment. Would you like me to provide guidance on where you can find this information, or is there anything else I can assist you with?\n"]}],"source":["start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"70bee62a","metadata":{"id":"70bee62a","outputId":"67466274-7c3a-4fba-bf92-d986b4cc21d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","completed\n","It looks like the document with the relevant stock price information is not available at the moment. If you have specific dates or periods in mind for which you'd like to compare the closing prices of particular stocks, please let me know. I can guide you on where to find this data, or if you have the information, you may provide the dates and stock symbols for comparison.\n"]}],"source":["user_message = \"What is the difference between the closing prices of \"\n","\"Microsoft's stock (MSFT) on March 31, 2023, and April 3, 2023?\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = thread\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"484e2638","metadata":{"id":"484e2638","outputId":"5aeb0a21-0045-4733-d5f6-60b6c3d9bdca"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","in_progress\n","completed\n","It seems like I don't have access to the specific stock volume traded on February 8, 2023, for Apple (AAPL). If you have access to a financial news website, a stock market analysis platform, or a trading platform, you should be able to find this information by searching for the historical trading volume of Apple's stock (AAPL) on that date. If you need any guidance on how to access this information, please feel free to ask.\n"]}],"source":["user_message = \"What volume of Apple's stock was traded (AAPL) on February 8, 2023?\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = thread\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"41b3febf","metadata":{"id":"41b3febf","outputId":"edaff793-7301-4f8a-fa59-209861d78000"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","completed\n","It seems that I'm encountering difficulties in retrieving the specific information you requested regarding Apple's stock on February 7, 2023. If there are any other details or topics you'd like to explore, please feel free to ask, and I'll be glad to assist you.\n"]}],"source":["user_message = \"On February 7, 2023, what was the percentage \"\n","\"change between the opening and closing prices of Google's stock (GOOG)\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = thread\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"e7f56c61","metadata":{"id":"e7f56c61","outputId":"3ad24417-00ef-4ad4-90da-23cd3f4e8b16"},"outputs":[{"data":{"text/plain":["AssistantDeleted(id='asst_vxlG2wUhI6voBX9Yv9MKP8ou', deleted=True, object='assistant.deleted')"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["client.beta.assistants.delete(assistant.id)"]},{"cell_type":"code","execution_count":null,"id":"17eaeb58","metadata":{"id":"17eaeb58","outputId":"a32d5c8b-07e3-465c-adde-acdde6c4a16c"},"outputs":[{"data":{"text/plain":["ThreadDeleted(id='thread_id4Nb9PNxAfVxthGHsPgouWS', deleted=True, object='thread.deleted')"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["client.beta.threads.delete(thread.id)"]},{"cell_type":"code","execution_count":null,"id":"377d4ccc","metadata":{"id":"377d4ccc","outputId":"a84af36e-f345-4840-a668-6a32b4c0b06d"},"outputs":[{"data":{"text/plain":["Assistant(id='asst_nUpOMVgXbVQ8mSweR6CYcTsw', created_at=1702643025, description=None, file_ids=['file-UssQzQwFO05DG3iH4FRnIcx8'], instructions='You are a stock market analyst specializing in financial markets and investments. Provide well-researched and up-to-date information on stock trends, investment strategies, and market analysis. Use the documents provided as a knowledge base to answer questions.', metadata={}, model='gpt-3.5-turbo-1106', name='Stock Market Analyst', object='assistant', tools=[ToolRetrieval(type='retrieval')])"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["assistant = create_assistant(\n","    name = name,\n","    instructions = instructions,\n","    file = file\n",")\n","\n","assistant"]},{"cell_type":"code","execution_count":null,"id":"4e137674","metadata":{"id":"4e137674","outputId":"807b024e-6a4f-4a53-e9bb-e0adf23e0f54"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","completed\n","The difference between the closing prices of the stock on February 7, 2023 (which was $154.64999389648438) and April 6, 2023 (which was $163.75999450683594), is $9.110000610351562.\n"]}],"source":["user_message = \"What is the difference between the closing prices of \"\n","\"Microsoft's stock (MSFT) on March 31, 2023, and April 3, 2023?\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = None\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"642d911d","metadata":{"id":"642d911d","outputId":"e1981b29-5aa6-4174-e222-4018b2917f58"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","in_progress\n","completed\n","The volume of Apple's stock (AAPL) traded on February 8, 2023, was 625320029source.\n"]}],"source":["user_message = \"What volume of Apple's stock was traded (AAPL) on February 8, 2023?\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = thread\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"bc520a94","metadata":{"id":"bc520a94","outputId":"1f28b2f7-74e5-429b-8f25-886d75df4087"},"outputs":[{"name":"stdout","output_type":"stream","text":["in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","in_progress\n","completed\n","To calculate the percentage change for February 7, 2023, we can use the following formula:\n","\n","\\[ \\text{Percentage change} = \\frac{(\\text{Closing price on February 7, 2023} - \\text{Closing price on February 6, 2023})}{\\text{Closing price on February 6, 2023}} \\times 100\\% \\]\n","\n","After substituting the values, we get:\n","\n","\\[ \\text{Percentage change} = \\frac{(154.64999389648438 - 154.4142303466797)}{154.4142303466797} \\times 100\\% \\]\n","\n","Calculating this, we find:\n","\n","\\[ \\text{Percentage change} \\approx \\frac{0.2357635498046875}{154.4142303466797} \\times 100\\% \\approx 0.153\\% \\]\n","\n","So, the percentage change in the closing price of AAPL stock on February 7, 2023, was approximately 0.153%.\n"]}],"source":["user_message = \"On February 7, 2023, what was the percentage \"\n","\"change between the opening and closing prices of Google's stock (GOOG)\"\n","\n","thread = start_interaction(\n","    user_message = user_message,\n","    thread = thread\n",")\n","\n","start_assistant(assistant, thread)"]},{"cell_type":"code","execution_count":null,"id":"07dac493","metadata":{"id":"07dac493"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"openai_venv","language":"python","name":"openai_venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
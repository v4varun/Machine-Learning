# -*- coding: utf-8 -*-
"""AttentionMechanism.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GiK9T2l5n4RSCi7i0M65VpK_7PfkBdGU
"""

import numpy as np
import tensorflow as tf

"""Referred link- https://machinelearningmastery.com/the-attention-mechanism-from-scratch/

Firstly, calculating the attention for the first word in a sequence of four. Then  we would be calculating an attention output for all four words in matrix form.

First defining the word embeddings of the four different words to calculate the attention. In actual practice, these word embeddings would have been generated by an encoder; however, for this particular example, you will define them manually.
"""

word_1 = tf.constant([[0, 1, 1, 2]])
word_2 = tf.constant([[1, 0, 0, 2]])
word_3 = tf.constant([[1, 1, 0, 2]])
word_4 = tf.constant([[2, 1, 1, 1]])

"""Stacking  the word embeddings into a single array"""

word_emb_stack = tf.stack([word_1, word_2, word_3, word_4], axis = 1)

word_emb_stack

"""generating the weight matrices, which you will eventually multiply to the word embeddings to generate the queries, keys, and values. Here, you shall generate these weight matrices randomly; however, in actual practice, these would have been learned during training."""

shape = (4, 4)

W_Q = tf.random.uniform(shape = shape, minval = 0, maxval = 3, dtype = tf.int32)
W_K = tf.random.uniform(shape = shape, minval = 0, maxval = 3, dtype = tf.int32)
W_V = tf.random.uniform(shape = shape, minval = 0, maxval = 3, dtype = tf.int32)

W_Q, W_K, W_V

"""Notice how the number of rows of each of these matrices is equal to the dimensionality of the word embeddings (which in this case is four) to allow us to perform the matrix multiplication.

Subsequently, the query, key, and value vectors for each word are generated by multiplying each word embedding by each of the weight matrices.
"""

# generating the queries, keys and values
query_1 = tf.matmul(word_1, W_Q)
key_1 = tf.matmul(word_1, W_K)
value_1 = tf.matmul(word_1, W_V)

query_2 = tf.matmul(word_2, W_Q)
key_2 = tf.matmul(word_2, W_K)
value_2 = tf.matmul(word_2, W_V)

query_3 = tf.matmul(word_3, W_Q)
key_3 = tf.matmul(word_3, W_K)
value_3 = tf.matmul(word_3, W_V)

query_4 = tf.matmul(word_4, W_Q)
key_4 = tf.matmul(word_4, W_K)
value_4 = tf.matmul(word_4, W_V)

"""Checking query, key and value for first word"""

query_1, key_1, value_1

"""Scoring the first query vector against all key vectors"""

scores = tf.stack([
    tf.matmul(query_1, key_1, transpose_b = True),
    tf.matmul(query_1, key_2, transpose_b = True),
    tf.matmul(query_1, key_3, transpose_b = True),
    tf.matmul(query_1, key_4, transpose_b = True)]
)

scores

"""The score values are subsequently passed through a softmax operation to generate the weights. Before doing so, it is common practice to divide the score values by the square root of the dimensionality of the key vectors (in this case, three) to keep the gradients stable."""

weights = tf.nn.softmax(
    tf.cast(tf.squeeze(scores), tf.float32) / tf.math.sqrt(tf.cast(tf.shape(key_1)[-1], tf.float32))
)

weights

"""Converting value tensors into float type"""

value_1 = tf.cast(value_1, tf.float32)
value_2 = tf.cast(value_2, tf.float32)
value_3 = tf.cast(value_3, tf.float32)
value_4 = tf.cast(value_4, tf.float32)

"""Computing the attention by a weighted sum of the value vectors.
This attention scores are for word_1
"""

attention = (weights[0] * value_1) + (weights[1] * value_2) + (weights[2] * value_3) + (weights[3] * value_4)

print(attention)

"""For faster processing, the same calculations can be implemented in matrix form to generate an attention output for all four words in one go:

Generating the queries, keys and values
"""

word_emb_stack

word_emb_stack = tf.squeeze(word_emb_stack)

word_emb_stack

Query = word_emb_stack @ W_Q
Key = word_emb_stack @ W_K
Value = word_emb_stack @ W_V

Query, Key, Value

"""Getting the score vectors from the query vectors against all key vectors"""

scores = tf.matmul(Query, Key, transpose_b = True)

scores

"""Calculating  the weights by a softmax operation"""

weights = tf.nn.softmax(tf.cast(scores, tf.float32) / tf.math.sqrt(tf.cast(tf.shape(Key)[-1], tf.float32)))

weights

"""Finally computing the attention by a weighted sum of the value vectors"""

attention = tf.matmul(weights, tf.cast(Value, tf.float32))

attention

